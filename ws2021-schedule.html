<!DOCTYPE HTML>
<!--
	Imagination by TEMPLATED
    templated.co @templatedco
    Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>SIGTYP -- Workshop 2021 Preliminary Schedule</title>
		<link rel="shortcut icon" type="image/x-icon" href="images/favicon.ico" />
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="sigtyp,sigtyp2021,naacl,workshop,typology,linguistics,multilinguality" />
		<link href='http://fonts.googleapis.com/css?family=Raleway:400,100,200,300,500,600,700,800,900' rel='stylesheet' type='text/css'>
		<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  		<!--script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script-->
  		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
		<script src="js/skel.min.js"></script>
			<script src="js/skel-panels.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel-noscript.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-desktop.css" />
		</noscript>

		
		<!--Q/A display-->
		<script>
		  function resizeIframe(obj) {
	    		obj.style.height = obj.contentWindow.document.documentElement.scrollHeight  + 'px';
			obj.style.height = '20px';
  			}
		</script>
		<style>
			.forumlink {
			border-width:2pt;
			margin:auto; display:table;
			font-size: 14pt;
			background:#eaeaea;
			color:#000050;
			text-align:center; border:1px solid #0060e0; padding:4px 15px 4px 15px
			}
			.forumlink:hover {
			background:#a0a0ff; color:white; 
			}
			
			</style>



	</head>
	<body>

	<div id="header-wrapper">

		<!-- Header -->
			<div id="header">
				<div class="container">
						
					<!-- Logo -->
						<div id="logo">
							<a href="index.html"><img src="images/sigtyp1.jpg"  style="width:70px" alt="SIGTYP"></a>
							<!--h1><a href="#"><font color=red>S</font>IG<font color=red>T</font>YP</a></h1-->
						</div>
					
					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Homepage</a></li>
								<li><a href="constitution.html">Constitution</a></li>
								<li><a href="members.html">Members</a></li>
								<li class="active"><a href="workshop.html">Workshop</a></li>
								<li><a href="blog.html">Blog</a></li>
							</ul>
						</nav>
	
				</div>
			</div>
		<!-- Header -->

		<!-- Banner -->
			<div id="banner">
				<div class="container">
	
					<section>
						<!--span class="fa fa-cubes"></span-->
						<header>
							<h2 > </h2>
							<h2 > </h2>
<h2 > </h2>
							<span class="byline"> </span>
						</header>
						<!--a href="#" class="button medium">Fusce ultrices fringilla</a-->
					</section>	
				</div>
			</div>
		<!-- /Banner -->

	</div>

	<!-- Main -->
		<div id="main">
			<div class="container">
				<div class="row">
		
					<!--div class="3u">
						<section class="sidebar">
							<header>
								<h2>News</h2>
							</header>
							
                         <a class="twitter-timeline" data-width="500" data-height="600" data-theme="light" href="https://twitter.com/sigtyp_acl?ref_src=twsrc%5Etfw">Tweets by SIGTYP</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
							<!--header>
								<h2>Feugiat Tempus</h2>
							</header>
							<ul class="default">
								<li><a href="#">Maecenas luctus lectus at sapien</a></li>
								<li><a href="#">Etiam rhoncus volutpat erat</a></li>
								<li><a href="#">Donec dictum metus in sapien</a></li>
								<li><a href="#">Nulla luctus eleifend purus</a></li>
								<li><a href="#">Maecenas luctus lectus at sapien</a></li>
							</ul>

						</section>
						<!--section class="sidebar">
							<header>
								<h2>Nulla eleifend</h2>
							</header>
							<ul class="default">
								<li><a href="#">Maecenas luctus lectus at sapien</a></li>
								<li><a href="#">Donec dictum metus in sapien</a></li>
								<li><a href="#">Integer gravida nibh quis urna</a></li>
								<li><a href="#">Etiam posuere augue sit amet nisl</a></li>
								<li><a href="#">Mauris vulputate dolor sit amet nibh</a></li>
							</ul>
						</section>
					</div-->
				
					<div class="container">
						<section>
							<header>
				<h2>  <font color="red">S</font><font color="yellow">I</font><font color="green">G</font><font color="brown">T</font><font color="blue">Y</font><font color="purple">P</font>2021 — JUNE,10th — ONLINE</h2> </header>

<hr/>							
<p style="font-size:18px">

<strong>Time zone: TBA</strong>
							</p>
  <div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse1" style="font-size:18px">TBA  Opening Session</a>
        </h4>
      </div>
      <div id="collapse1" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By SIGTYP2021 Organizing Committee</p>
<p>
Opening remarks: general comments about SIGTYP development, SIGTYP2021 submissions, shared task, etc. 
</p>

</div>
      </div>
    </div>

<br/> 
<h3 style="font-size:21px"><font color="green">&nbsp;Morphology Module&nbsp;</font></h3><br/>
 <p style="font-size:18px"> &nbsp;&nbsp;&nbsp;Registration: <a href="https://forms.gle/FfwgGsKzYaYtRobR6">https://forms.gle/FfwgGsKzYaYtRobR6</a> </p>
<br/>  
<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#ktalk-morphology">Time TBA: Keynote Talk by David Yarowsky &nbsp;&nbsp;&nbsp; Live Q&A Session: TBA</a>
        </h4>
      </div>
      <div id="ktalk-morphology" class="panel-collapse collapse">
        <div class="panel-body">
<p>
<img src="workshops/2021/keynotes/david-yarowsky.jpeg" alt="David Yarowsky" style="height:110px;float:left;margin:9px"/>
David Yarowsky is Professor of computer science and a member of the Center for Language and Speech Processing at Johns Hopkins University.
David’s research focuses on word sense disambiguation, minimally supervised induction algorithms in NLP, and multilingual natural language processing. He earned his bachelor’s (’87) in computer science at Harvard University and his master’s (’93) and Ph.D. (’96) in computer and information science at the University of Pennsylvania.
</p>
<p  align="center"><a href="TBA"  class="button small">Slides</a>&nbsp;&nbsp;<a href="TBA"  class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/keynote-david"  class="button small">RocketChat</a>&nbsp;&nbsp;<a href="http://www.cs.jhu.edu/~yarowsky/"  class="button small">David's Website</a></p>
       </div>
      </div>
    </div>


    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-2">Time TBA: Inferring Morphological Complexity from Syntactic Dependency Networks: A Test </a>
        </h4>
      </div>
      <div id="paper-2" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:blue"> By Guglielmo Inglese and Luca Brigada Villa</p>
<p align="left">
Research in linguistic typology has shown that languages do not fall into the neat morphological types (synthetic vs. analytic) postulated in the 19th century. Instead, analytic and synthetic must be viewed as two poles of a continuum and languages may show a mix analytic and synthetic strategies to different degrees. Unfortunately, empirical studies that offer a more fine-grained morphological classification of languages based on these parameters remain few. In this paper, we build upon previous research by Liu & Xu (2011) and investigate the possibility of inferring information on morphological complexity from syntactic dependency networks.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/69-pGdy2nOE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  align="center"><a href="https://TBA"  class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-2"  class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.2.pdf"  class="button small">Paper</a></p>

       </div>
      </div>
    </div>

   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-12">Time TBA: Information-Theoretic Characterization of Morphological Fusion (Extended Abstract) </a>
        </h4>
      </div>
      <div id="paper-12" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Neil Rathi, Michael Hahn and Richard Futrell</p>
<p>
Traditionally, morphological typology divides synthetic languages into two broad groups (e.g. von Schlegel,1808; von Humboldt, 1843).  Agglutinative languages, such as Turkish, segment morphemes into inde-pendent features which can be easily split. On the other hand, fusional languages, such as Latin, “fuse”morphemes together phonologically (Bickel and Nichols, 2013).  At the same time, there has long beenrecognition that the categories “agglutinative” and “fusional” are best thought of as a matter of degree,with Greenberg (1954) developing an “index of agglutination” metric for languages.  Here, we proposean information-theoretic definition of the fusion of any given form in a language, which naturally deliversa graded measure of the degree of fusion.  We use a sequence-to-sequence model to empirically verifythat our measure captures typical linguistic classifications.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-12" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/12.pdf"  class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-23">Time TBA: Morph Call: Probing Morphosyntactic Content of Multilingual Transformers </a>
        </h4>
      </div>
      <div id="paper-23" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Vladislav Mikhailov, Oleg Serikov and Ekaterina Artemova</p>
<p>
The outstanding performance of transformer-based language models on a great variety of NLP and NLU tasks has stimulated interest in exploration of their inner workings. Recent research has been primarily focused on higher-level and complex linguistic phenomena such as syntax, semantics, world knowledge and common-sense. The majority of the studies is anglocentric, and little remains known regarding other languages, specifically their morphosyntactic properties. To this end, our work presents Morph Call, a suite of 46 probing tasks for four Indo-European languages of different morphology: Russian, French, English and German. We propose a new type of probing tasks based on detection of guided sentence perturbations. We use a combination of neuron-, layer- and representation-level introspection techniques to analyze the morphosyntactic content of four multilingual transformers, including their understudied distilled versions. Besides, we examine how fine-tuning on POS-tagging task affects the probing performance.</p>
<p  align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-23" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.10.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-15">Time TBA: Measuring Prefixation and Suffixation in the Languages of the World </a>
        </h4>
      </div>
      <div id="paper-15" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Harald Hammarström</p>
<p align="left">
It has long been recognized that suffixing is more common than prefixing in the languages of the world. More detailed statistics on this tendency are needed to sharpen proposed explanations for this tendency. The classic approach to gathering data on the prefix/suffix preference is for a human to read grammatical descriptions (948 languages), which is time-consuming and involves discretization judgments. In this paper we explore two machine-driven approaches for prefix and suffix statistics which are crude approximations, but have advantages in terms of time and replicability. The first simply searches a large collection of grammatical descriptions for occurrences of the terms ‘prefix’ and ‘suffix’ (4 287 languages). The second counts substrings from raw text data in a way indirectly reflecting prefixation and suffixation (1 030 languages, using New Testament translations). The three approaches largely agree in their measurements but there are important theoretical and practical differences. In all measurements, there is an overall preference for suffixation, albeit only slightly, at ratios ranging between 0.51 and 0.68.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sB623XTDVWo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="sigtyp.inf.ethz.ch/channel/paper-15" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.8.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-18">Time TBA: Predicting and Explaining French Grammatical Gender </a>
        </h4>
      </div>
      <div id="paper-18" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Saumya Sahai and Dravyansh Sharma</p>
<p>
Grammatical gender may be determined by semantics, orthography, phonology, or could even be arbitrary. Identifying patterns in the factors that govern noun genders can be useful for language learners, and for understanding innate linguistic sources of gender bias. Traditional manual rule-based approaches may be substituted by more accurate and scalable but harder-to-interpret computational approaches for predicting gender from typological information. In this work, we propose interpretable gender classification models for French, which obtain the best of both worlds. We present high accuracy neural approaches which are augmented by a novel global surrogate based approach for explaining predictions. We introduce ‘auxiliary attributes’ to provide tunable explanation complexity.</p>
<p  align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-18" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.9.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-8">Time TBA: Quantitative Detection of Cognacy in the Predictive Structure of Inflection Classes: Romance Verbal Conjugations Against the Broader Typological Variation (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-8" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Borja Herce and Balthasar Bickel</p>
<p align="left">
n recent years, Information Theory (with its core notion of entropy) has provided the theoretical back-ground for a lot of empirical research on inflectional systems, and has inspired various metrics to capture(different aspects of) their complexity.  So far, however, entropy-based metrics have chiefly been usedto assess synchronic states.  Here we explore their potential for capturing patterns in language changeand phylogenetic relatedness. Specifically, we probe different aspects of an inflectional system for theirstability within one language family, Romance, and for the degree to which they distinguish this familyfrom unrelated and less closely related languages.  Based on most metrics, Romance appears to be dif-ferent from the control sample in the mean, variance, or both.  The difference in variance is particularlyinteresting because it might suggest differences in relative diachronic stability and as phylogenetic sig-nals of relatedness.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/t0L8Q0uaSow" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-8" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/8.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

<br/> 
<h3 style="font-size:21px"><font color="purple">&nbsp;Low-Resource Languages Module&nbsp;</font></h3><br/>
  <p style="font-size:18px"> &nbsp;&nbsp;&nbsp;Registration: <a href="https://forms.gle/XJUJdvfgsxtHEkTn7">https://forms.gle/XJUJdvfgsxtHEkTn7</a> </p>
<br/>

<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#ktalk-lowresource">Time TBA: Keynote Talk by Miryam de Lhoneux &nbsp;&nbsp;&nbsp; Live Q&A Session: TBA</a>
        </h4>
      </div>
      <div id="ktalk-lowresource" class="panel-collapse collapse">
        <div class="panel-body">
<p>
<img src="workshops/2021/keynotes/miryam-de-lhoneux.jpeg" alt="Miryam de Lhoneux" style="height:110px;float:left;margin:9px"/>
Miryam de Lhoneux is a Postdoctoral Researcher at Uppsala University, KU Leuven and the University of Copenhagen.
Miryam's research interests are centered around three main themes in the domain of AI and language: syntactic parsing, typology and interpretability. She finds syntactic parsing an exciting area because it allows exploring interesting linguistic phenomena while working on a system that is central to NLP and useful to many applications.
</p>
<p align="center"><a href="TBA" class="button small">Slides</a>&nbsp;&nbsp;<a href="TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/keynote-miryam" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://cl.lingfil.uu.se/~miryam/research.html" class="button small">Miryam's Website</a></p>
       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-14">Time TBA: Family of Origin and Family of Choice: Massively Parallel Lexiconized Iterative Pretraining for Severely Low Resource Machine Translation </a>
        </h4>
      </div>
      <div id="paper-14" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:blue"> By Zhong Zhou and Alexander Waibel</p>
<p align="left">
We translate a closed text that is known in advance into a severely low resource language by leveraging massive source parallelism. In other words, given a text in 124 source languages, we translate it into a severely low resource language using only ∼1,000 lines of low resource data without any external help. Firstly, we propose a systematic method to rank and choose source languages that are close to the low resource language. We call the linguistic definition of language family Family of Origin (FAMO), and we call the empirical definition of higher-ranked languages using our metrics Family of Choice (FAMC). Secondly, we build an Iteratively Pretrained Multilingual Order-preserving Lexiconized Transformer (IPML) to train on ∼1,000 lines (∼3.5%) of low resource data. In order to translate named entities well, we build a massive lexicon table for 2,939 Bible named entities in 124 source languages, and include many that occur once and covers more than 66 severely low resource languages. Moreover, we also build a novel method of combining translations from different source languages into one. Using English as a hypothetical low resource language, we get a +23.9 BLEU increase over a multilingual baseline, and a +10.3 BLEU increase over our asymmetric baseline in the Bible dataset. We get a 42.8 BLEU score for Portuguese-English translation on the medical EMEA dataset. We also have good results for a real severely low resource Mayan language, Eastern Pokomchi.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/rMRMUTx3LKE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1Z64y1d7Az/" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-14" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.7.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-27">Time TBA: Towards Figurative Language Generation in Afrikaans (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-27" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Imke van Heerden and Anil Bas (Extended Abstract)</p>
<p>
This paper presents an LSTM-based approach to figurative language generation, which is an importantstep towards creative text generation in Afrikaans.  Due to the scarcity of resources (in comparison toresource-rich languages),  we train the proposed network on a single literary novel.   This follows thesame approach as Van Heerden and Bas (2021), however, we explicitly focus and expand on fully au-tomatic text generation,  centring on figurative language in particular.   The proposed model generatesphrases that contain compellingly novel figures of speech such as metaphor, simile and personification.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-27" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/27.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-13">Time TBA: Graph Convolutional Network for Swahili News Classification (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-13" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Alexandros Kastanos and Tyler Martin</p>
<p  align="left">
In this work, we demonstrate the ability of Text Graph Convolutional Network (Text GCN) to surpassthe performance of traditional natural language processing benchmarks on the task of semi-supervised Swahili news categorisation. Our experiments highlight the more severely label-restricted context oftenfacing low-resourced African languages. We build on this finding by presenting a memory-efficient variant of Text GCN which replaces the naive one-hot node representation with a bag of words representation.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Xf4-8UeRAPc" title="YouTube video player" frameborder="0" style="display: block; margin: auto;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1QA411G7V7" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-13" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/13.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-26">Time TBA: Let-Mi: An Arabic Levantine Twitter Dataset for Misogynistic Language (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-26" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Hala Mulki and Bilal Ghanem</p>
<p>
Misogyny  is  one  type  of  hate  speech  that  disparages  a  person  or  a  group  having  the  female  genderidentity; it is typically defined as hatred of or contempt for women. Online misogyny has become an increasing worry for Arab women who experience gender-based online abuse on a daily basis. Such online abuse can be expressed through several misogynistic behaviors which reinforce and justify underestimation of women, male superiority, sexual abuse, mistreatment, and violence against women.  Misogyny automatic detection systems can assist in the prohibition of anti-women Arabic toxic content. Developing these systems is hindered by the lack of the Arabic misogyny benchmark datasets. In this work, we introduce an Arabic Levantine Twitter dataset for Misogynistic language (LeT-Mi) to be the first benchmark dataset for Arabic misogyny.  The proposed dataset consists of 6,550 tweets annotated either as neutral (misogynistic-free) or as one of seven misogyny categories: discredit, dominance, cursing/damning, sex-ual harassment, stereotyping and objectification, derailing, and the threat of violence. We further provide a detailed review of the dataset creation and annotation phases. The consistency of the annotations for the proposed dataset was emphasized through inter-rater agreement evaluation measures. Moreover, Let-Mi was used as an evaluation dataset through binary, multi-class, and target classification tasks which were conducted by several state-of-the-art machine learning systems along with Multi-Task Learning (MTL) configuration.  The obtained results indicated that the performances achieved by the used systems are consistent with state-of-the-art results for languages other than Arabic, while employing MTL improved the performance of the misogyny/target classification tasks.
<br/>
Our dataset is available at <a href="https://github.com/bilalghanem/let-mi">https://github.com/bilalghanem/let-mi</a></p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-26" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/26.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-6">Time TBA: Improving Cross-Lingual Sentiment Analysis via Conditional Language Adversarial Adaptation </a>
        </h4>
      </div>
      <div id="paper-6" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Hemanth Kandula and Bonan Min</p>
<p>
Sentiment analysis has come a long way for high-resource languages due to the availability of large annotated corpora. However, it still suffers from lack of training data for low-resource languages. To tackle this problem, we propose Conditional Language Adversarial Network (CLAN), an end-to-end neural architecture for cross-lingual sentiment analysis without cross-lingual supervision. CLAN differs from prior work in that it allows the adversarial training to be conditioned on both learned features and the sentiment prediction, to increase discriminativity for learned representation in the cross-lingual setting. Experimental results demonstrate that CLAN outperforms previous methods on the multilingual multi-domain Amazon review dataset. 
<br/>
Our source code is released at <a href="https://github.com/hemanthkandula/clan">https://github.com/hemanthkandula/clan</s></p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-6" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.4.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-17">Time TBA: Multilingual Slot and Intent Detection (xSID) with Cross-lingual Auxiliary Tasks (Extended Abstract) </a>
        </h4>
      </div>
      <div id="paper-17" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Rob van der Goot, Ibrahim Sharaf, Aizhan Imankulova, Ahmet Üstün, Marija Stepanović, Alan Ramponi, Siti Oryza Khairunnisa, Mamoru Komachi and Barbara Plank</p>
<p align="left">
Digital assistants are becoming an integral part of everyday life. However, commercial digital assistants are only available for a limited set of languages (as of March 2020, between 8 to around 20 languages). Because of this, a vast amount of people can not use these devices in their native tongue.  In this work, we focus on two core tasks within the digital assistant pipeline:  intent classification and slot detection.Intent classification recovers the goal of the utterance, whereas slot detection identifies important prop-erties regarding this goal. Besides introducing a novel cross-lingual dataset for these tasks, consisting of 13 languages, we evaluate a variety of models:  1) multilingually pre-trained transformer-based models,2) we supplement these models with auxiliary tasks to evaluate whether multi-task learning can be beneficial, and 3) annotation transfer with neural machine translation.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/DH0C-n_p6h0" title="YouTube video player" frameborder="0" style="display: block; margin: auto;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1qf4y1Y7u8" class="button small">Bilibili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-17" class="button small">Rocketchat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/17.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-25">Time TBA: Unsupervised Self-Training for Unsupervised Cross-Lingual Transfer (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-25" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Akshat Gupta, Sai Krishna Rallabandi and Alan W Black</p>
<p>
Labelled data is scarce, especially for low-resource languages.  This beckons the need to come up with unsupervised methods for natural language processing tasks. In this paper, we introduce a general frame-work called Unsupervised Self-Training, capable of unsupervised cross-lingual transfer.  We apply our proposed framework to a two-class sentiment analysis problem of code-switched data. We use the power of pre-trained BERT models for initialization and fine-tune them in an unsupervised manner, only using pseudo labels produced by zero-shot predictions.  We test our algorithm on multiple code-switched languages. Our unsupervised models compete well with their supervised counterparts, with their performance reaching within 1-7% (weighted F1 scores) when compared to supervised models trained for a two-class problem.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-25" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/25.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<br/> 
<h3 style="font-size:21px"><font color="orange">&nbsp;Typological Knowledge in NLP Module&nbsp;</font></h3><br/>
  <p style="font-size:18px"> &nbsp;&nbsp;&nbsp;Registration: <a href="https://forms.gle/maPPcL88aAaYJp3A6">https://forms.gle/maPPcL88aAaYJp3A6</a> </p>
<br/>

<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#ktalk-typological-knowledge">Time TBA: Keynote Talk by Johannes Bjerva &nbsp;&nbsp;&nbsp; Live Q&A Session: TBA</a>
        </h4>
      </div>
      <div id="ktalk-typological-knowledge" class="panel-collapse collapse">
        <div class="panel-body">
<p>
<img src="https://sigtyp.io/workshops/2021/keynotes/johannes-bjerva.jpeg" alt="Johannes Bjerva" style="height:110px;float:left;margin:9px"/>
Johannes Bjerva is a tenure-track Assistant Professor affiliated with the Database and Web-technologies (DW) research group at the Department of Computer Science, Aalborg University. His research generally deals with under-resourced languages, which he approaches by combining linguistic typology with parameter sharing via multilingual and multitask learning. For the past few years, he has investigated computational typology and answering typological research questions for this purpose, typically using deep learning techniques.
</p>
<p align="center"><a href="TBA" class="button small">Slides</a>&nbsp;&nbsp;<a href="TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/keynote-johannes" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://bjerva.github.io/" class="button small">Johannes' Website</a></p>
       </div>
      </div>
    </div>


 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-7">Time TBA: Improving the Performance of UDify with Linguistic Typology Knowledge</a>
        </h4>
      </div>
      <div id="paper-7" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Chinmay Choudhary</p>
<p>
UDify is the state-of-the-art language-agnostic dependency parser which is trained on a polyglot corpus of 75 languages. This multilingual modeling enables the model to generalize over unknown/lesser-known languages, thus leading to improved performance on low-resource languages. In this work we used linguistic typology knowledge available in URIEL database, to improve the cross-lingual transferring ability of UDify even further.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-7" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.5.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-10">Time TBA: FrameNet and Typology</a>
        </h4>
      </div>
      <div id="paper-10" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Michael Ellsworth, Collin Baker and Miriam R. L. Petruck</p>
<p>
FrameNet and the Multilingual FrameNet project have produced multilingual semantic annotations of parallel texts that yield extremely fine-grained typological insights. Moreover, frame semantic annotation of a wide cross-section of languages would provide information on the limits of Frame Semantics (Fillmore 1982, Fillmore1985). Multilingual semantic annotation offers critical input for research on linguistic diversity and recurrent patterns in computational typology. Drawing on results from FrameNet annotation of parallel texts, this paper proposes frame semantic annotation as a new component to complement the state of the art in computational semantic typology.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-10" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.6.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-16">Time TBA: Exploring Linguistic Typology Features in Multilingual Machine Translation (Extended Abstract)</a>
        </h4>
      </div>
     <div id="paper-16" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Oscar Moreno and Arturo Oncevay</p>
<p align="left">
We  explore  whether  linguistic  typology  features  can  impact  multilingual  machine  translation  performance (many-to-English) by using initial pseudo-tokens and factored language-level embeddings. With 20 languages from different families or groups, we observed that the features of “Order of Subject (S),Object (O) and Verb (V)”, “Position of Negative Word with respect to S-O-V” and “Prefixing vs.  Suf-fixing in Inflectional Morphology” provided slight improvements in low-resource language-pairs despite not overcoming the average performance for all languages.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-16" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/16.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-5">Time TBA: A Universal Dependencies Corpora Maintenance Methodology Using Downstream Application</a>
        </h4>
      </div>
      <div id="paper-5" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Ran Iwamoto, Hiroshi Kanayama, Alexandre Rademaker and Takuya Ohko</p>
<p>
This paper investigates updates of Universal Dependencies (UD) treebanks in 23 languages and their impact on a downstream application. Numerous people are involved in updating UD’s annotation guidelines and treebanks in various languages. However, it is not easy to verify whether the updated resources maintain universality with other language resources. Thus, validity and consistency of multilingual corpora should be tested through application tasks involving syntactic structures with PoS tags, dependency labels, and universal features. We apply the syntactic parsers trained on UD treebanks from multiple versions (2.0 to 2.7) to a clause-level sentiment extractor. We then analyze the relationships between attachment scores of dependency parsers and performance in application tasks. For future UD developments, we show examples of outputs that differ depending on version.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-5" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.3.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-11">Time TBA: A Look to Languages through the Glass of BPE Compression (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-11" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Ximena Gutierrez-Vasques, Tanja Samardzic and Christian Bentz</p>
<p>
One of the predominant methods for subword tokenization is Byte-pair encoding (BPE). Originally, this is a data compression technique based on replacing the most common pair of consecutive bytes with a new symbol. When applied to text, each iteration merges two adjacent symbols;  this can be seen as a process of going from characters to subwords through iterations.
<br/>
Regardless of the language, the first merge operations tend to have a stronger impact on the compression of texts, i.e., they capture very frequent patterns that lead to a reduction of redundancy and to an increment of the text entropy. However, the natural language properties that allow this compression are rarely analyzed, i.e., do all languages get compressed in the same way through BPE merge operations?  We hypothesize that the type of recurrent patterns captured in each merge depends on the typology and even orthography and other corpus-related phenomena.  For instance, for some languages, this compression might be related to frequent affixes or regular inflectional morphs, while for some others, it might be related to more idiosyncratic, irregular patterns or even related to orthographic redundancies. <br/>We propose a novel way to quantify this, inspired by the notion of morphological productivity.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-11" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="http://" class="button small">Paper</a></p>
       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-28">Time TBA: Improving Access to Untranscribed Speech by Leveraging Spoken Term Detection and Self-supervised Learning of Speech Representations (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-28" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Nay San, Martijn Bartelds and Dan Jurafsky</p>
<p>
We summarise findings from our recent work showing that a large self-supervised model trained only on English speech provides a noise-robust and speaker-invariant feature extraction method that can be used for a speech information retrieval task with unrelated low resource target languages.  A qualitative error analysis also revealed that the majority of the retrieval errors could be attributed to the differences in phonological inventories between English and the evaluation languages.  With a longer-term aim of leveraging typological information to better adapt such models for the target languages, we also report on work in progress which examines the phonetic information encoded in these representations.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-28" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/28.pdf" class="button small">Paper</a></p>
       </div>
      </div>
    </div>


<br/> 
<h3 style="font-size:21px"><font color="green">&nbsp;Linguistic Typology Module&nbsp;</font></h3><br/>
 <p style="font-size:18px"> &nbsp;&nbsp;&nbsp; Registration: <a href="https://forms.gle/bAL1KXPDWHjMx7D66">https://forms.gle/bAL1KXPDWHjMx7D66</a> </p>
<br/>

<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#ktalk-ling-typology">Time TBA: Keynote Talk by Claire Bowern &nbsp;&nbsp;&nbsp; Live Q&A Session: TBA</a>
        </h4>
      </div>
      <div id="ktalk-ling-typology" class="panel-collapse collapse">
        <div class="panel-body">
<p>
<img src="workshops/2021/keynotes/claire-bowern.jpeg" alt="Claire Bowern" style="height:110px;float:left;margin:9px"/>
Claire Bowern is Professor of linguistics at Yale University.
Claire is a historical linguist whose research is centered around language change and language documentation in Indigenous Australia. Since 2015 she has served as the vice president of the Endangered Language Fund. While her work touches many areas, the overarching question is how to characterize the nature of language change. Language change involves a complex interplay of universal properties of language acquisition and production and community-specific social factors; her research program looks at how to study this so we understand both the micro change(es) in progress and the macro change that leads to language families. She works with speakers of endangered languages, with archival sound and print materials, and she uses computational and phylogenetic methods. 
</p>
<p  align="center"><a href="TBA" class="button small">Slides</a>&nbsp;&nbsp;<a href="TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/keynote-claire" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://ling.yale.edu/people/claire-bowern" class="button small">Claire's Website</a></p>
       </div>
      </div>
    </div>



 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-1">Time TBA: OTEANN: Estimating the Transparency of Orthographies with an Artificial Neural Network </a>
        </h4>
      </div>
      <div id="paper-1" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:blue"> By Xavier Marjou</p>
<p align="left">
To transcribe spoken language to written medium, most alphabets enable an unambiguous sound-to-letter rule. However, some writing systems have distanced themselves from this simple concept and little work exists in Natural Language Processing (NLP) on measuring such distance. In this study, we use an Artificial Neural Network (ANN) model to evaluate the transparency between written words and their pronunciation, hence its name Orthographic Transparency Estimation with an ANN (OTEANN). Based on datasets derived from Wikimedia dictionaries, we trained and tested this model to score the percentage of false predictions in phoneme-to-grapheme and grapheme-to-phoneme translation tasks. The scores obtained on 17 orthographies were in line with the estimations of other studies. Interestingly, the model also provided insight into typical mistakes made by learners who only consider the phonemic rule in reading and writing.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/tQ1V3yLgfhk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-1" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.1.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-21">Time TBA: Modeling Linguistic Typology - A Probabilistic Graphical Models Approach (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-21" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Xia Lu</p>
<p>
n this paper, we propose to use probabilistic graphical models as a new theoretical and computational framework  to  study  linguistic  typology.   The  graphical  structure  of  such  a  model  represents  a  meta-language that consists of linguistic variables and the relationships between them while the parameters associated with each variable can be used to infer the strength of the relationships between the variables. Such models can also be used to predict feature values of new languages. Besides providing better solutions to existing problems in linguistic typology such a framework opens up to many new research topics that can help us to gain further insights into linguistic typology.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-21" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/21.pdf" class="button small">Paper</a></p>
       </div>
      </div>
    </div>


 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-4">Time TBA: On the Universality of Lexical Concepts (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-4" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Bradley Hauer and Grzegorz Kondrak</p>
<p align="left">
We posit that lexicalized concepts are universal, and thus can be annotated cross-linguistically in parallel corpora. This is one of the implications of a novel theory that formalizes the relationship between words and senses in both monolingual and multilingual settings. The theory is based on a unifying treatment ofthe notions of synonymy and translational equivalence as different aspects of the relation of sameness of meaning within and across languages.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Ha5c7NH8lEk" title="YouTube video player" frameborder="0" style="display: block; margin: auto;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-4" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/4.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-9">Time TBA: Subword Geometry: Picturing Word Shapes (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-9" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Olga Sozinova and Tanja Samardzic</p>
<p>
In this work in progress, we are investigating the structural properties of subwords in 20 languages by extracting word shapes, i.e. sequences of subword lengths.</p>
<p  align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-9" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/9.pdf"  class="button small">Paper</a></p>

       </div>
      </div>
    </div>


 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-20">Time TBA: Plugins for Structurally Varied Languages in XMG Framework (Extended Abstract)</a>
        </h4>
      </div>
      <div id="paper-20" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Valeria Generalova</p>
<p>
This paper aims to suggest an XMG-based design of metagrammatical classes storing language-specific information on a multilingual grammar engineering project.  It also presents a method of reusing the information from WALS. The principal claim is the hierarchy of features and the modular architecture of feature structures.
</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-20" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/20.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<br/>
<h3 style="font-size:21px"><font color="blue">&nbsp;Shared Task Module&nbsp;</font></h3><br/>


 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#shared-task">Time TBA: Shared Task 2021 Overview </a>
        </h4>
      </div>
      <div id="shared-task" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Elizabeth Salesky, Badr Abdullah, and Sabrina Mielke</p>
<p>
While language identification is a fundamental speech and language processing task, for many languages and language families it remains a challenging task. For many low-resource and endangered languages this is in part due to resource availability: where larger datasets exist, they may be single-speaker or have different domains than desired application scenarios, demanding a need for domain and speaker-invariant language identification systems. This year’s shared task on robust spoken language identification sought to investigate just this scenario: systems were to be trained on largely single-speaker speech from one domain, but evaluated on data in other domains recorded from speakers under different recording circumstances, mimicking realistic low-resource scenarios. We see that domain and speaker mismatch proves very challenging for current methods which can perform above 95% accuracy in-domain, which domain adaptation can address to some degree, but that these conditions merit further investigation to make spoken language identification accessible in many scenarios.</p>
<p  align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/shared-task" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.11.pdf"  class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-24">Time TBA: Language ID Prediction from Speech Using Self-Attentive Pooling and 1D-Convolutions </a>
        </h4>
      </div>
      <div id="paper-24" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Roman Bedyakin and Nikolay Mikhaylovskiy</p>
<p>
This memo describes NTR-TSU submission for SIGTYP 2021 Shared Task on predicting language IDs from speech. Spoken Language Identification (LID) is an important step in a multilingual Automated Speech Recognition (ASR) system pipeline. For many low-resource and endangered languages, only single-speaker recordings may be available, demanding a need for domain and speaker-invariant language ID systems. In this memo, we show that a convolutional neural network with a Self-Attentive Pooling layer shows promising results for the language identification task.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-24" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.12.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-29">Time TBA: A ResNet-50-based Convolutional Neural Network Model for Language ID Identification from Speech Recordings</a>
        </h4>
      </div>
      <div id="paper-29" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Giuseppe Celano</p>
<p>
This paper describes the model built for the SIGTYP 2021 Shared Task aimed at identifying 18 typologically different languages from speech recordings. Mel-frequency cepstral coefficients derived from audio files are transformed into spectrograms, which are then fed into a ResNet-50-based CNN architecture. The final model achieved validation and test accuracies of 0.73 and 0.53, respectively.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-29" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.13.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-31">Time TBA: Anlirika: An LSTM–CNN Flow Twister for Spoken Language Identification</a>
        </h4>
      </div>
      <div id="paper-31" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Andreas Scherbakov, Liam Whittle, Ritesh Kumar, Siddharth Singh, Matthew Coleman and Ekaterina Vylomova</p>
<p>
The paper presents Anlirika’s submission to SIGTYP 2021 Shared Task on Robust Spoken Language Identification. The task aims at building a robust system that generalizes well across different domains and speakers. The training data is limited to a single domain only with predominantly single speaker per language while the validation and test data samples are derived from diverse dataset and multiple speakers. We experiment with a neural system comprising a combination of dense, convolutional, and recurrent layers that are designed to perform better generalization and obtain speaker-invariant representations. We demonstrate that the task in its constrained form (without making use of external data or augmentation the train set with samples from the validation set) is still challenging. Our best system trained on the data augmented with validation samples achieves 29.9% accuracy on the test data.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/paper-31" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.14.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

<br/>
<h3 style="font-size:21px"><font color="cyan">&nbsp;Socialization Module&nbsp;</font></h3><br/>
 <div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse30" style="font-size:18px">Time TBA: Linguistic Trivia Games</a>
        </h4>
      </div>
      <div id="collapse30" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By SIGTYP2021 Organizing Committee</p>
<p>
TBA
</p>

   </div>
      </div>
    </div>


<div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse32" style="font-size:18px">Time TBA: Open Mic Discussion</a>
        </h4>
      </div>
      <div id="collapse32" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By SIGTYP2021 Organizing Committee</p>
<p>
TBA
</p>

</div>
      </div>
    </div>



<br/>

<br/>
  <div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse31" style="font-size:18px">Time TBA: Closing Session</a>
        </h4>
      </div>
      <div id="collapse31" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By SIGTYP2021 Organizing Committee</p>
<p>
Closing Remarks and SIGTYP 2022 Announcement! 
</p>

</div>
      </div>
    </div>

</div>
<br/>
<br/>


<!--p style="font-size:18px">You may also <a href="http://">Read it in PDF</a></p-->

						</section>
					</div>
					
				</div>
			</div>
		</div>
	
	<!-- Copyright -->
		<div id="copyright">
			<div class="container">
				Contact Email: <a href="mailto:sigtyp AT gmail DOT com"> sigtyp AT gmail DOT com </a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  WebMaster: <a href="http://kat.academy">EKATERINA VYLOMOVA</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Design: <a href="http://templated.co">TEMPLATED</a>
			</div>
		</div>
 <script>
        if (location.hash !== null && location.hash !== "") {
            $(location.hash + ".collapse").collapse("show");
        }
    </script>

	</body>
</html>
