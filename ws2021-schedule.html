<!DOCTYPE HTML>
<!--
	Imagination by TEMPLATED
    templated.co @templatedco
    Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>SIGTYP -- Workshop 2021 Preliminary Schedule</title>
		<link rel="shortcut icon" type="image/x-icon" href="images/favicon.ico" />
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="sigtyp,sigtyp2021,naacl,workshop,typology,linguistics,multilinguality" />
		<link href='http://fonts.googleapis.com/css?family=Raleway:400,100,200,300,500,600,700,800,900' rel='stylesheet' type='text/css'>
		<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  		<!--script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script-->
  		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
		<script type="text/javascript" src="js/moment.js"></script>
		<script type="text/javascript" src="js/moment-timezone.js"></script>
		<script type="text/javascript" src="js/timezones.js"></script>
		<script src="js/skel.min.js"></script>
			<script src="js/skel-panels.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel-noscript.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-desktop.css" />
		</noscript>

		
		<!--Q/A display-->
		<script>
		  function resizeIframe(obj) {
	    		obj.style.height = obj.contentWindow.document.documentElement.scrollHeight  + 'px';
			obj.style.height = '20px';
  			}
		</script>
		<style>
			.forumlink {
			border-width:2pt;
			margin:auto; display:table;
			font-size: 14pt;
			background:#eaeaea;
			color:#000050;
			text-align:center; border:1px solid #0060e0; padding:4px 15px 4px 15px
			}
			.forumlink:hover {
			background:#a0a0ff; color:white; 
			}
			
			</style>



	</head>
	<body>

	<div id="header-wrapper">

		<!-- Header -->
			<div id="header">
				<div class="container">
						
					<!-- Logo -->
						<div id="logo">
							<a href="index.html"><img src="images/sigtyp1.jpg"  style="width:70px" alt="SIGTYP"></a>
							<!--h1><a href="#"><font color=red>S</font>IG<font color=red>T</font>YP</a></h1-->
						</div>
					
					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Homepage</a></li>
								<li><a href="constitution.html">Constitution</a></li>
								<li><a href="members.html">Members</a></li>
								<li class="active"><a href="workshop.html">Workshop</a></li>
								<li><a href="lectures.html">Lectures</a></li>
								<li><a href="blog.html">Blog</a></li>
							</ul>
						</nav>
	
				</div>
			</div>
		<!-- Header -->

		<!-- Banner -->
			<div id="banner">
				<div class="container">
	
					<section>
						<!--span class="fa fa-cubes"></span-->
						<header>
							<h2 > </h2>
							<h2 > </h2>
<h2 > </h2>
							<span class="byline"> </span>
						</header>
						<!--a href="#" class="button medium">Fusce ultrices fringilla</a-->
					</section>	
				</div>
			</div>
		<!-- /Banner -->

	</div>

	<!-- Main -->
		<div id="main">
			<div class="container">
				<div class="row">
		
					
				
					<div class="container">
						<section>
							<header>
				<h2>  <font color="red">S</font><font color="yellow">I</font><font color="green">G</font><font color="brown">T</font><font color="blue">Y</font><font color="purple">P</font>2021 — JUNE,10th — ONLINE</h2> </header>

<p style="font-size:18px"><strong>
The schedule for different time zones is also available <a href="https://docs.google.com/spreadsheets/d/1yI-UyPQ4v2FxX89F8lWdaToC-lOakRKkbzeYXixs8AQ/edit?usp=sharing"> here </strong></a>
</p>
<p style="font-size:16px">The workshop is (largely) single-track this year. There is going to be one Zoom call that lasts for 24 hours. The idea is that each module is repeated. The scheduling was done to ensure that everyone could attend the modules they are interested in (where interest was expressed on our Google doc) at a reasonable time. The schedule shows the time of the modules in many popular time zones. Note that the number of the session does not indicate different content: Morphology 1 and Morphology 2 have the same content but different people. The authors of the work will likely only be at one of the modules, namely the one that is in their time zone. During each session, we will play each pre-recorded talk and then run live Q&A (time slots for all talks are provided below). If you cannot attend a session you're presenting in, we will collect questions and put them in the corresponding RocketChat channel.</p>

<hr style="border-top: dotted 2px;"/>						
<p style="font-size:18px">

<strong>Choose your time zone: </strong>
							</p>


      <select id="timezone-select" class="form-control"></select>
<br/>

<p class="modtime" style="font-size:18px"> &nbsp;&nbsp;Starts: <font data-time="2021-06-09 18:00">06:00 PM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-09 18:15">06:15 PM</font></p>
  <div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse1" style="font-size:18px">Opening Session by Edoardo Ponti</a>
        </h4>
      </div>
      <div id="collapse1" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Edoardo Ponti</p>
<p>
Opening remarks: general comments about SIGTYP development, SIGTYP2021 submissions, shared task, etc. 
</p>

</div>
      </div>
    </div>

<br/> 
<h3 style="font-size:21px"><font color="green">&nbsp;Morphology Module&nbsp;</font></h3><br/>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 1 &nbsp;&nbsp;Starts: <font data-time="2021-06-09 18:15">06:15 PM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-09 20:30">08:30 PM</font> <br/> &nbsp;&nbsp;&nbsp; (Moderators: Ryan Cotterell, Eleanor Chodroff)</p>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 2 &nbsp;&nbsp;Starts: <font data-time="2021-06-09 22:30">10:30 PM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-10 01:00">01:00 AM</font> <br/> &nbsp;&nbsp;&nbsp; (Moderators: Khuyagbaatar Batsuren, Ekaterina Vylomova, Ryan Cotterell)</p>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 3 &nbsp;&nbsp;Starts: <font data-time="2021-06-10 11:00">11:00 AM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-10 13:30">13:30 PM</font> <br/> &nbsp;&nbsp;&nbsp; (Moderators: Gabriella Lapesa, Edoardo Ponti, Ryan Cotterell, Josef Valvoda)</p>
 <p style="font-size:18px"> &nbsp;&nbsp;&nbsp;Registration: <a href="https://forms.gle/FfwgGsKzYaYtRobR6">https://forms.gle/FfwgGsKzYaYtRobR6</a> </p>
<br/>  
<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#ktalk-morphology"> Keynote Talk by David Yarowsky: Bible-based Morphology, Typology and NLP in 1000+ Languages (1 hour)</a>
        </h4>
      </div>
      <div id="ktalk-morphology" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:red;font-size:16px">Keynote Talk by David Yarowsky: Bible-based Morphology, Typology and NLP in 1000+ Languages (1 hour)</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-09 18:15">--</font> &ndash; <font data-time="2021-06-09 19:15">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-09 22:30">--</font> &ndash; <font data-time="2021-06-09 23:30">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 11:00">--</font> &ndash; <font data-time="2021-06-10 12:00">--</font></p>
<p align="left">
<img src="workshops/2021/keynotes/david-yarowsky.jpeg" alt="David Yarowsky" style="height:110px;float:left;margin:9px"/>
David Yarowsky is Professor of computer science and a member of the Center for Language and Speech Processing at Johns Hopkins University.
David’s research focuses on word sense disambiguation, minimally supervised induction algorithms in NLP, and multilingual natural language processing. He earned his bachelor’s (’87) in computer science at Harvard University and his master’s (’93) and Ph.D. (’96) in computer and information science at the University of Pennsylvania.
</p>
<p  align="center"><a href="TBA"  class="button small">Slides</a>&nbsp;&nbsp;<a href="TBA"  class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-keynote-david"  class="button small">RocketChat</a>&nbsp;&nbsp;<a href="http://www.cs.jhu.edu/~yarowsky/"  class="button small">David's Website</a></p>
       </div>
      </div>
    </div>


    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-2"> Inferring Morphological Complexity from Syntactic Dependency Networks: A Test (10 min)</a>
        </h4>
      </div>
      <div id="paper-2" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Inferring Morphological Complexity from Syntactic Dependency Networks: A Test</p>
<p align="left" style="color:blue"> By Guglielmo Inglese and Luca Brigada Villa</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-09 19:15">--</font> &ndash; <font data-time="2021-06-09 19:25">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-09 23:30">--</font> &ndash; <font data-time="2021-06-09 23:40">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 12:00">--</font> &ndash; <font data-time="2021-06-10 12:10">--</font></p>
<p align="left">
Research in linguistic typology has shown that languages do not fall into the neat morphological types (synthetic vs. analytic) postulated in the 19th century. Instead, analytic and synthetic must be viewed as two poles of a continuum and languages may show a mix analytic and synthetic strategies to different degrees. Unfortunately, empirical studies that offer a more fine-grained morphological classification of languages based on these parameters remain few. In this paper, we build upon previous research by Liu & Xu (2011) and investigate the possibility of inferring information on morphological complexity from syntactic dependency networks.
</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/69-pGdy2nOE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  align="center"><a href="https://www.bilibili.com/video/BV1DB4y1u7qF"  class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-2"  class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.2.pdf"  class="button small">Paper</a></p>

       </div>
      </div>
    </div>

   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-12">Information-Theoretic Characterization of Morphological Fusion, Extended Abstract (10 min) </a>
        </h4>
      </div>
      <div id="paper-12" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Information-Theoretic Characterization of Morphological Fusion</p>
<p align="left" style="color:blue"> By Neil Rathi, Michael Hahn and Richard Futrell</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-09 19:25">--</font> &ndash; <font data-time="2021-06-09 19:35">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-09 23:40">--</font> &ndash; <font data-time="2021-06-09 23:50">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 12:10">--</font> &ndash; <font data-time="2021-06-10 12:20">--</font></p>
<p align="left">
Traditionally, morphological typology divides synthetic languages into two broad groups (e.g. von Schlegel,1808; von Humboldt, 1843).  Agglutinative languages, such as Turkish, segment morphemes into inde-pendent features which can be easily split. On the other hand, fusional languages, such as Latin, “fuse”morphemes together phonologically (Bickel and Nichols, 2013).  At the same time, there has long beenrecognition that the categories “agglutinative” and “fusional” are best thought of as a matter of degree,with Greenberg (1954) developing an “index of agglutination” metric for languages.  Here, we proposean information-theoretic definition of the fusion of any given form in a language, which naturally deliversa graded measure of the degree of fusion.  We use a sequence-to-sequence model to empirically verifythat our measure captures typical linguistic classifications.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/J2Hm1ekkmkM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1rq4y1j7Ak" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-12" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/12.pdf"  class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-23">Morph Call: Probing Morphosyntactic Content of Multilingual Transformers (15 min)</a>
        </h4>
      </div>
      <div id="paper-23" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Morph Call: Probing Morphosyntactic Content of Multilingual Transformers</p>
<p align="left" style="color:blue"> By Vladislav Mikhailov, Oleg Serikov and Ekaterina Artemova</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-09 19:25">--</font> &ndash; <font data-time="2021-06-09 19:40">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-09 23:40">--</font> &ndash; <font data-time="2021-06-10 23:55">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 12:10">--</font> &ndash; <font data-time="2021-06-10 12:25">--</font></p>
<p align="left">
The outstanding performance of transformer-based language models on a great variety of NLP and NLU tasks has stimulated interest in exploration of their inner workings. Recent research has been primarily focused on higher-level and complex linguistic phenomena such as syntax, semantics, world knowledge and common-sense. The majority of the studies is anglocentric, and little remains known regarding other languages, specifically their morphosyntactic properties. To this end, our work presents Morph Call, a suite of 46 probing tasks for four Indo-European languages of different morphology: Russian, French, English and German. We propose a new type of probing tasks based on detection of guided sentence perturbations. We use a combination of neuron-, layer- and representation-level introspection techniques to analyze the morphosyntactic content of four multilingual transformers, including their understudied distilled versions. Besides, we examine how fine-tuning on POS-tagging task affects the probing performance.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/fGCDk1JrETQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  align="center"><a href="https://www.bilibili.com/video/BV1P54y157NV" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-23" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.10.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-15">Measuring Prefixation and Suffixation in the Languages of the World (15 min)</a>
        </h4>
      </div>
      <div id="paper-15" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Measuring Prefixation and Suffixation in the Languages of the World</p>
<p align="left" style="color:blue"> By Harald Hammarström</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-09 19:40">--</font> &ndash; <font data-time="2021-06-09 19:55">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-09 23:55">--</font> &ndash; <font data-time="2021-06-10 00:10">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 12:25">--</font> &ndash; <font data-time="2021-06-10 12:40">--</font></p>
<p align="left">
It has long been recognized that suffixing is more common than prefixing in the languages of the world. More detailed statistics on this tendency are needed to sharpen proposed explanations for this tendency. The classic approach to gathering data on the prefix/suffix preference is for a human to read grammatical descriptions (948 languages), which is time-consuming and involves discretization judgments. In this paper we explore two machine-driven approaches for prefix and suffix statistics which are crude approximations, but have advantages in terms of time and replicability. The first simply searches a large collection of grammatical descriptions for occurrences of the terms ‘prefix’ and ‘suffix’ (4 287 languages). The second counts substrings from raw text data in a way indirectly reflecting prefixation and suffixation (1 030 languages, using New Testament translations). The three approaches largely agree in their measurements but there are important theoretical and practical differences. In all measurements, there is an overall preference for suffixation, albeit only slightly, at ratios ranging between 0.51 and 0.68.</p>
<iframe src="https://drive.google.com/file/d/1bW1dcPrslsHN3FNNJiDjYoRrKlRhCB3Q/preview" width="560" height="315" allowfullscreen></iframe>
<p  align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-15" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.8.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-18">Predicting and Explaining French Grammatical Gender (15 min)</a>
        </h4>
      </div>
      <div id="paper-18" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Predicting and Explaining French Grammatical Gender</p>
<p align="left" style="color:blue"> By Saumya Sahai and Dravyansh Sharma</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-09 19:55">--</font> &ndash; <font data-time="2021-06-09 20:10">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-10 00:10">--</font> &ndash; <font data-time="2021-06-10 00:25">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 12:40">--</font> &ndash; <font data-time="2021-06-10 12:55">--</font></p>
<p align="left">
Grammatical gender may be determined by semantics, orthography, phonology, or could even be arbitrary. Identifying patterns in the factors that govern noun genders can be useful for language learners, and for understanding innate linguistic sources of gender bias. Traditional manual rule-based approaches may be substituted by more accurate and scalable but harder-to-interpret computational approaches for predicting gender from typological information. In this work, we propose interpretable gender classification models for French, which obtain the best of both worlds. We present high accuracy neural approaches which are augmented by a novel global surrogate based approach for explaining predictions. We introduce ‘auxiliary attributes’ to provide tunable explanation complexity.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/S0zjKLc-z0Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  align="center"><a href="https://www.bilibili.com/video/BV1Z44y1z7uj" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-18" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.9.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-8">Quantitative Detection of Cognacy in the Predictive Structure of Inflection Classes: Romance Verbal Conjugations Against the Broader Typological Variation, Extended Abstract (15 min)</a>
        </h4>
      </div>
      <div id="paper-8" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Quantitative Detection of Cognacy in the Predictive Structure of Inflection Classes: Romance Verbal Conjugations Against the Broader Typological Variation</p>
<p align="left" style="color:blue"> By Borja Herce and Balthasar Bickel</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-09 20:10">--</font> &ndash; <font data-time="2021-06-09 20:25">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-10 00:25">--</font> &ndash; <font data-time="2021-06-10 00:40">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 12:55">--</font> &ndash; <font data-time="2021-06-10 13:10">--</font></p>
<p align="left">
In recent years, Information Theory (with its core notion of entropy) has provided the theoretical back-ground for a lot of empirical research on inflectional systems, and has inspired various metrics to capture(different aspects of) their complexity.  So far, however, entropy-based metrics have chiefly been usedto assess synchronic states.  Here we explore their potential for capturing patterns in language changeand phylogenetic relatedness. Specifically, we probe different aspects of an inflectional system for theirstability within one language family, Romance, and for the degree to which they distinguish this familyfrom unrelated and less closely related languages.  Based on most metrics, Romance appears to be dif-ferent from the control sample in the mean, variance, or both.  The difference in variance is particularlyinteresting because it might suggest differences in relative diachronic stability and as phylogenetic sig-nals of relatedness.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/t0L8Q0uaSow" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV15o4y127a2" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-8" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/8.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

<br/> 
<h3 style="font-size:21px"><font color="purple">&nbsp;Low-Resource Languages Module&nbsp;</font></h3><br/>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 1 &nbsp;&nbsp;Starts: <font data-time="2021-06-10 01:00">01:00 AM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-10 03:30">03:30 AM</font> <br/> &nbsp;&nbsp;&nbsp; (Moderators: Khuyagbaatar Batsuren, Ekaterina Vylomova, Ryan Cotterell)</p>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 2 &nbsp;&nbsp;Starts: <font data-time="2021-06-10 05:30">05:30 AM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-10 08:00">08:00 AM</font> <br/> &nbsp;&nbsp;&nbsp; (Moderators: Ryan Cotterell)</p>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 3 &nbsp;&nbsp;Starts: <font data-time="2021-06-10 13:30">1:30 PM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-10 16:00">04:00 PM</font> <br/> &nbsp;&nbsp;&nbsp; (Moderators: Edoardo Ponti, Irene Nikkarinen, Ryan Cotterell, Josef Valvoda)</p>
  <p style="font-size:18px"> &nbsp;&nbsp;&nbsp;Registration: <a href="https://forms.gle/XJUJdvfgsxtHEkTn7">https://forms.gle/XJUJdvfgsxtHEkTn7</a> </p>
<br/>
<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#ktalk-lowresource">Keynote Talk by Miryam de Lhoneux: Low-resource NLP: Lessons from Dependency Parsing (45 min)</a>
        </h4>
      </div>
      <div id="ktalk-lowresource" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Keynote Talk by Miryam de Lhoneux: Low-resource NLP: Lessons from Dependency Parsing</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-10 01:00">--</font> &ndash; <font data-time="2021-06-10 01:45">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-10 05:30">--</font> &ndash; <font data-time="2021-06-10 06:15">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 13:30">--</font> &ndash; <font data-time="2021-06-10 14:15">--</font></p>
<p align="left">
<img src="workshops/2021/keynotes/miryam-de-lhoneux.jpeg" alt="Miryam de Lhoneux" style="height:110px;float:left;margin:9px"/>
Miryam de Lhoneux is a Postdoctoral Researcher at Uppsala University, KU Leuven and the University of Copenhagen.
Miryam's research interests are centered around three main themes in the domain of AI and language: syntactic parsing, typology and interpretability. She finds syntactic parsing an exciting area because it allows exploring interesting linguistic phenomena while working on a system that is central to NLP and useful to many applications.
<br/>
This talk is about low-resource NLP, with a primary focus on dependency parsing. I first argue that the Universal Dependencies (UD) dataset is ahead of the game when it comes to typologically diverse NLP and that we can use it to investigate important questions in multilingual NLP. We can ask whether techniques such as transfer learning or the use of typological information can mitigate the gap in language technology between low and high-resource languages. I review studies using these two techniques in dependency parsing and conclude that transfer learning works surprisingly well for related languages but that our current methods do not work well for low-resource languages which do not have a related high-resource language. I suggest that the use of typological information is underexploited and is a promising research line. I finally discuss work on low-resource NLP beyond dependency parsing, namely, our participation in the machine translation shared task for indigenous languages of the Americas. This task turns out to be even harder than expected. I conclude the talk by suggesting that there is still a lot of work to do for typologically diverse NLP and by highlighting recent community efforts which are building new datasets and are slowly making it possible to put multilinguality at the core of NLP.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/HrzrlhMnde0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2021/keynotes/delhoneux_sigtyp21_slides.pdf" class="button small">Slides</a>&nbsp;&nbsp;<a href="TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-keynote-miryam" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://cl.lingfil.uu.se/~miryam/research.html" class="button small">Miryam's Website</a></p>
       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-14">Family of Origin and Family of Choice: Massively Parallel Lexiconized Iterative Pretraining for Severely Low Resource Machine Translation (15 min)</a>
        </h4>
      </div>
      <div id="paper-14" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Family of Origin and Family of Choice: Massively Parallel Lexiconized Iterative Pretraining for Severely Low Resource Machine Translation</p>
<p align="left" style="color:blue"> By Zhong Zhou and Alexander Waibel</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-10 01:45">--</font> &ndash; <font data-time="2021-06-10 02:00">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-10 06:15">--</font> &ndash; <font data-time="2021-06-10 06:30">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 14:15">--</font> &ndash; <font data-time="2021-06-10 14:30">--</font></p>
<p align="left">
We translate a closed text that is known in advance into a severely low resource language by leveraging massive source parallelism. In other words, given a text in 124 source languages, we translate it into a severely low resource language using only ∼1,000 lines of low resource data without any external help. Firstly, we propose a systematic method to rank and choose source languages that are close to the low resource language. We call the linguistic definition of language family Family of Origin (FAMO), and we call the empirical definition of higher-ranked languages using our metrics Family of Choice (FAMC). Secondly, we build an Iteratively Pretrained Multilingual Order-preserving Lexiconized Transformer (IPML) to train on ∼1,000 lines (∼3.5%) of low resource data. In order to translate named entities well, we build a massive lexicon table for 2,939 Bible named entities in 124 source languages, and include many that occur once and covers more than 66 severely low resource languages. Moreover, we also build a novel method of combining translations from different source languages into one. Using English as a hypothetical low resource language, we get a +23.9 BLEU increase over a multilingual baseline, and a +10.3 BLEU increase over our asymmetric baseline in the Bible dataset. We get a 42.8 BLEU score for Portuguese-English translation on the medical EMEA dataset. We also have good results for a real severely low resource Mayan language, Eastern Pokomchi.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/rMRMUTx3LKE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1Z64y1d7Az/" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-14" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.7.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-27">Towards Figurative Language Generation in Afrikaans, Extended Abstract (15 min)</a>
        </h4>
      </div>
      <div id="paper-27" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Towards Figurative Language Generation in Afrikaans</p>
<p align="left" style="color:blue"> By Imke van Heerden and Anil Bas (Extended Abstract)</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-10 02:00">--</font> &ndash; <font data-time="2021-06-10 02:15">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-10 06:30">--</font> &ndash; <font data-time="2021-06-10 06:45">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 14:30">--</font> &ndash; <font data-time="2021-06-10 14:45">--</font></p>
<p align="left">
This paper presents an LSTM-based approach to figurative language generation, which is an importantstep towards creative text generation in Afrikaans.  Due to the scarcity of resources (in comparison toresource-rich languages),  we train the proposed network on a single literary novel.   This follows thesame approach as Van Heerden and Bas (2021), however, we explicitly focus and expand on fully au-tomatic text generation,  centring on figurative language in particular.   The proposed model generatesphrases that contain compellingly novel figures of speech such as metaphor, simile and personification.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/5ujuLSLGItE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV15h411e7Ga" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-27" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/27.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-13">Graph Convolutional Network for Swahili News Classification, Extended Abstract (15 min)</a>
        </h4>
      </div>
      <div id="paper-13" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Graph Convolutional Network for Swahili News Classification</p>
<p align="left" style="color:blue"> By Alexandros Kastanos and Tyler Martin</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-10 02:15">--</font> &ndash; <font data-time="2021-06-10 02:30">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-10 06:45">--</font> &ndash; <font data-time="2021-06-10 07:00">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 14:45">--</font> &ndash; <font data-time="2021-06-10 15:00">--</font></p>
<p  align="left">
In this work, we demonstrate the ability of Text Graph Convolutional Network (Text GCN) to surpassthe performance of traditional natural language processing benchmarks on the task of semi-supervised Swahili news categorisation. Our experiments highlight the more severely label-restricted context oftenfacing low-resourced African languages. We build on this finding by presenting a memory-efficient variant of Text GCN which replaces the naive one-hot node representation with a bag of words representation.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Xf4-8UeRAPc" title="YouTube video player" frameborder="0" style="display: block; margin: auto;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1QA411G7V7" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-13" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/13.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-26">Let-Mi: An Arabic Levantine Twitter Dataset for Misogynistic Language, Extended Abstract (15 min)</a>
        </h4>
      </div>
      <div id="paper-26" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Let-Mi: An Arabic Levantine Twitter Dataset for Misogynistic Language </p>
<p align="left" style="color:blue"> By Hala Mulki and Bilal Ghanem</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-10 02:30">--</font> &ndash; <font data-time="2021-06-10 02:45">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-10 07:00">--</font> &ndash; <font data-time="2021-06-10 07:15">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 15:00">--</font> &ndash; <font data-time="2021-06-10 15:15">--</font></p>
<p align="left">
Misogyny  is  one  type  of  hate  speech  that  disparages  a  person  or  a  group  having  the  female  genderidentity; it is typically defined as hatred of or contempt for women. Online misogyny has become an increasing worry for Arab women who experience gender-based online abuse on a daily basis. Such online abuse can be expressed through several misogynistic behaviors which reinforce and justify underestimation of women, male superiority, sexual abuse, mistreatment, and violence against women.  Misogyny automatic detection systems can assist in the prohibition of anti-women Arabic toxic content. Developing these systems is hindered by the lack of the Arabic misogyny benchmark datasets. In this work, we introduce an Arabic Levantine Twitter dataset for Misogynistic language (LeT-Mi) to be the first benchmark dataset for Arabic misogyny.  The proposed dataset consists of 6,550 tweets annotated either as neutral (misogynistic-free) or as one of seven misogyny categories: discredit, dominance, cursing/damning, sex-ual harassment, stereotyping and objectification, derailing, and the threat of violence. We further provide a detailed review of the dataset creation and annotation phases. The consistency of the annotations for the proposed dataset was emphasized through inter-rater agreement evaluation measures. Moreover, Let-Mi was used as an evaluation dataset through binary, multi-class, and target classification tasks which were conducted by several state-of-the-art machine learning systems along with Multi-Task Learning (MTL) configuration.  The obtained results indicated that the performances achieved by the used systems are consistent with state-of-the-art results for languages other than Arabic, while employing MTL improved the performance of the misogyny/target classification tasks.
<br/>
Our dataset is available at <a href="https://github.com/bilalghanem/let-mi">https://github.com/bilalghanem/let-mi</a></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nOapC2MYxms" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1Ro4y1C7nc" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-26" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/26.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-6">Improving Cross-Lingual Sentiment Analysis via Conditional Language Adversarial Adaptation (15 min)</a>
        </h4>
      </div>
      <div id="paper-6" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Improving Cross-Lingual Sentiment Analysis via Conditional Language Adversarial Adaptation</p>
<p align="left" style="color:blue"> By Hemanth Kandula and Bonan Min</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-10 02:45">--</font> &ndash; <font data-time="2021-06-10 03:00">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-10 07:15">--</font> &ndash; <font data-time="2021-06-10 07:30">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 15:15">--</font> &ndash; <font data-time="2021-06-10 15:30">--</font></p>
<p align="left">
Sentiment analysis has come a long way for high-resource languages due to the availability of large annotated corpora. However, it still suffers from lack of training data for low-resource languages. To tackle this problem, we propose Conditional Language Adversarial Network (CLAN), an end-to-end neural architecture for cross-lingual sentiment analysis without cross-lingual supervision. CLAN differs from prior work in that it allows the adversarial training to be conditioned on both learned features and the sentiment prediction, to increase discriminativity for learned representation in the cross-lingual setting. Experimental results demonstrate that CLAN outperforms previous methods on the multilingual multi-domain Amazon review dataset. 
<br/>
Our source code is released at <a href="https://github.com/hemanthkandula/clan">https://github.com/hemanthkandula/clan</s></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/joD4dqwgBuA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1r5411M7jY" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-6" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.4.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-17">Multilingual Slot and Intent Detection (xSID) with Cross-lingual Auxiliary Tasks, Extended Abstract (15 min) </a>
        </h4>
      </div>
      <div id="paper-17" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Multilingual Slot and Intent Detection (xSID) with Cross-lingual Auxiliary Tasks</p>
<p align="left" style="color:blue"> By Rob van der Goot, Ibrahim Sharaf, Aizhan Imankulova, Ahmet Üstün, Marija Stepanović, Alan Ramponi, Siti Oryza Khairunnisa, Mamoru Komachi and Barbara Plank</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-10 03:00">--</font> &ndash; <font data-time="2021-06-10 03:15">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-10 07:30">--</font> &ndash; <font data-time="2021-06-10 07:45">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 15:30">--</font> &ndash; <font data-time="2021-06-10 15:45">--</font></p>
<p align="left">
Digital assistants are becoming an integral part of everyday life. However, commercial digital assistants are only available for a limited set of languages (as of March 2020, between 8 to around 20 languages). Because of this, a vast amount of people can not use these devices in their native tongue.  In this work, we focus on two core tasks within the digital assistant pipeline:  intent classification and slot detection.Intent classification recovers the goal of the utterance, whereas slot detection identifies important prop-erties regarding this goal. Besides introducing a novel cross-lingual dataset for these tasks, consisting of 13 languages, we evaluate a variety of models:  1) multilingually pre-trained transformer-based models,2) we supplement these models with auxiliary tasks to evaluate whether multi-task learning can be beneficial, and 3) annotation transfer with neural machine translation.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/DH0C-n_p6h0" title="YouTube video player" frameborder="0" style="display: block; margin: auto;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1qf4y1Y7u8" class="button small">Bilibili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-17" class="button small">Rocketchat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/17.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-25">Unsupervised Self-Training for Unsupervised Cross-Lingual Transfer, Extended Abstract (15 min)</a>
        </h4>
      </div>
      <div id="paper-25" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Unsupervised Self-Training for Unsupervised Cross-Lingual Transfer</p>
<p align="left" style="color:blue"> By Akshat Gupta, Sai Krishna Rallabandi and Alan W Black</p>
<p class="modtime" style="font-size:14px">&nbsp;&nbsp;S1: &nbsp;&nbsp;<font data-time="2021-06-10 03:15">--</font> &ndash; <font data-time="2021-06-10 03:30">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S2: &nbsp;&nbsp;<font data-time="2021-06-10 07:45">--</font> &ndash; <font data-time="2021-06-10 08:00">--</font>
&nbsp;&nbsp;┊┊&nbsp;&nbsp;S3: &nbsp;&nbsp;<font data-time="2021-06-10 15:45">--</font> &ndash; <font data-time="2021-06-10 16:00">--</font></p>
<p align="left">
Labelled data is scarce, especially for low-resource languages.  This beckons the need to come up with unsupervised methods for natural language processing tasks. In this paper, we introduce a general frame-work called Unsupervised Self-Training, capable of unsupervised cross-lingual transfer.  We apply our proposed framework to a two-class sentiment analysis problem of code-switched data. We use the power of pre-trained BERT models for initialization and fine-tune them in an unsupervised manner, only using pseudo labels produced by zero-shot predictions.  We test our algorithm on multiple code-switched languages. Our unsupervised models compete well with their supervised counterparts, with their performance reaching within 1-7% (weighted F1 scores) when compared to supervised models trained for a two-class problem.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/VELVXhI-cBM" title="YouTube video player" frameborder="0" style="display: block; margin: auto;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1TB4y1g7Eu" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-25" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/25.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<br/> 
<h3 style="font-size:21px"><font color="orange">&nbsp;Typological Knowledge in NLP Module&nbsp;</font></h3><br/>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 1 &nbsp;&nbsp;Starts: <font data-time="2021-06-10 03:30">03:30 AM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-10 05:30">05:30 AM</font> <br/> &nbsp;&nbsp;&nbsp;(Moderators: Ekaterina Vylomova)</p>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 2 &nbsp;&nbsp;Starts: <font data-time="2021-06-10 16:00">4:30 PM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-10 18:00">06:00 PM</font> <br/> &nbsp;&nbsp;&nbsp; (Moderators: Gabriella Lapesa, Elizabeth Salesky)</p>
  <p style="font-size:18px"> &nbsp;&nbsp;&nbsp;Registration: <a href="https://forms.gle/maPPcL88aAaYJp3A6">https://forms.gle/maPPcL88aAaYJp3A6</a> </p>
<br/>

<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#ktalk-typological-knowledge">Keynote Talk by Johannes Bjerva: Typological Feature Prediction and Blinding for Cross-Lingual NLP (45 min)</a>
        </h4>
      </div>
      <div id="ktalk-typological-knowledge" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Keynote Talk by Johannes Bjerva: Typological Feature Prediction and Blinding for Cross-Lingual NLP</p>
<p align="left">
<img src="https://sigtyp.io/workshops/2021/keynotes/johannes-bjerva.jpeg" alt="Johannes Bjerva" style="height:110px;float:left;margin:9px"/>
Johannes Bjerva is a tenure-track Assistant Professor affiliated with the Database and Web-technologies (DW) research group at the Department of Computer Science, Aalborg University. His research generally deals with under-resourced languages, which he approaches by combining linguistic typology with parameter sharing via multilingual and multitask learning. For the past few years, he has investigated computational typology and answering typological research questions for this purpose, typically using deep learning techniques.
<br/>
I will discuss the usefulness of typological features in NLP, with a focus on low-resource settings. On the one hand, typological features from databases such as the World Atlas of Language Structures (WALS) seem promising for cross-lingual NLP, as annotations for useful aspects of language exist even for very low-resource languages. Furthermore, missing features in WALS can be predicted with relatively high success, and has been the focus of much recent work (e.g. in the SIGTYP 2020 shared task). When it comes to application of these features, however, previous work has only found minor benefits from using typological information in actual NLP modelling. In recent work (EACL 2021), we hypothesised that these minor gains might stem from that a model trained in a cross-lingual setting picks up on typological cues from the input data, thus overshadowing the utility of explicitly using such features. We verify this hypothesis by blinding a model to typological information, and investigate how cross-lingual sharing and performance is impacted. While this sheds some light on the matter, the question of how to use typological information in NLP in the best way, seems to remain an open question.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/KOGrOyYtQdc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2021/keynotes/johannes_keynote_sigtyp_100621.pdf" class="button small">Slides</a>&nbsp;&nbsp;<a href="https://www.bilibili.com/video/BV1WB4y1g7Yg" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-keynote-johannes" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://bjerva.github.io/" class="button small">Johannes' Website</a></p>
       </div>
      </div>
    </div>


 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-7">Improving the Performance of UDify with Linguistic Typology Knowledge (15 min)</a>
        </h4>
      </div>
      <div id="paper-7" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Improving the Performance of UDify with Linguistic Typology Knowledge</p>
<p align="left" style="color:blue"> By Chinmay Choudhary</p>
<p align="left">
UDify is the state-of-the-art language-agnostic dependency parser which is trained on a polyglot corpus of 75 languages. This multilingual modeling enables the model to generalize over unknown/lesser-known languages, thus leading to improved performance on low-resource languages. In this work we used linguistic typology knowledge available in URIEL database, to improve the cross-lingual transferring ability of UDify even further.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/LIdgdzJ9Tl0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1zb4y1Z7Jp" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-7" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.5.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-10">FrameNet and Typology (15 min)</a>
        </h4>
      </div>
      <div id="paper-10" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:red;font-size:16px">FrameNet and Typology</p>
<p align="left" style="color:blue"> By Michael Ellsworth, Collin Baker and Miriam R. L. Petruck</p>
<p>
FrameNet and the Multilingual FrameNet project have produced multilingual semantic annotations of parallel texts that yield extremely fine-grained typological insights. Moreover, frame semantic annotation of a wide cross-section of languages would provide information on the limits of Frame Semantics (Fillmore 1982, Fillmore1985). Multilingual semantic annotation offers critical input for research on linguistic diversity and recurrent patterns in computational typology. Drawing on results from FrameNet annotation of parallel texts, this paper proposes frame semantic annotation as a new component to complement the state of the art in computational semantic typology.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-10" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.6.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-16">Exploring Linguistic Typology Features in Multilingual Machine Translation, Extended Abstract (15 min)</a>
        </h4>
      </div>
     <div id="paper-16" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Exploring Linguistic Typology Features in Multilingual Machine Translation</p>
<p align="left" style="color:blue"> By Oscar Moreno and Arturo Oncevay</p>
<p align="left">
We  explore  whether  linguistic  typology  features  can  impact  multilingual  machine  translation  performance (many-to-English) by using initial pseudo-tokens and factored language-level embeddings. With 20 languages from different families or groups, we observed that the features of “Order of Subject (S),Object (O) and Verb (V)”, “Position of Negative Word with respect to S-O-V” and “Prefixing vs.  Suf-fixing in Inflectional Morphology” provided slight improvements in low-resource language-pairs despite not overcoming the average performance for all languages.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/UwN_LydhLz8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1d64y1k77C" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-16" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/16.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-5">A Universal Dependencies Corpora Maintenance Methodology Using Downstream Application (15 min)</a>
        </h4>
      </div>
      <div id="paper-5" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">A Universal Dependencies Corpora Maintenance Methodology Using Downstream Application</p>
<p align="left" style="color:blue"> By Ran Iwamoto, Hiroshi Kanayama, Alexandre Rademaker and Takuya Ohko</p>
<p align="left">
This paper investigates updates of Universal Dependencies (UD) treebanks in 23 languages and their impact on a downstream application. Numerous people are involved in updating UD’s annotation guidelines and treebanks in various languages. However, it is not easy to verify whether the updated resources maintain universality with other language resources. Thus, validity and consistency of multilingual corpora should be tested through application tasks involving syntactic structures with PoS tags, dependency labels, and universal features. We apply the syntactic parsers trained on UD treebanks from multiple versions (2.0 to 2.7) to a clause-level sentiment extractor. We then analyze the relationships between attachment scores of dependency parsers and performance in application tasks. For future UD developments, we show examples of outputs that differ depending on version.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Kw5C5iLOGag" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1j44y167WN" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-5" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.3.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-11">A Look to Languages through the Glass of BPE Compression, Extended Abstract (15 min)</a>
        </h4>
      </div>
      <div id="paper-11" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">A Look to Languages through the Glass of BPE Compression</p>
<p align="left" style="color:blue"> By Ximena Gutierrez-Vasques, Tanja Samardzic and Christian Bentz</p>
<p align="left">
One of the predominant methods for subword tokenization is Byte-pair encoding (BPE). Originally, this is a data compression technique based on replacing the most common pair of consecutive bytes with a new symbol. When applied to text, each iteration merges two adjacent symbols;  this can be seen as a process of going from characters to subwords through iterations.
<br/>
Regardless of the language, the first merge operations tend to have a stronger impact on the compression of texts, i.e., they capture very frequent patterns that lead to a reduction of redundancy and to an increment of the text entropy. However, the natural language properties that allow this compression are rarely analyzed, i.e., do all languages get compressed in the same way through BPE merge operations?  We hypothesize that the type of recurrent patterns captured in each merge depends on the typology and even orthography and other corpus-related phenomena.  For instance, for some languages, this compression might be related to frequent affixes or regular inflectional morphs, while for some others, it might be related to more idiosyncratic, irregular patterns or even related to orthographic redundancies. <br/>We propose a novel way to quantify this, inspired by the notion of morphological productivity.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/jsPiDgKStnY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1Xq4y1j7EM" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-11" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/11.pdf" class="button small">Paper</a></p>
       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-28">Improving Access to Untranscribed Speech by Leveraging Spoken Term Detection and Self-supervised Learning of Speech Representations, Extended Abstract (15 min)</a>
        </h4>
      </div>
      <div id="paper-28" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Improving Access to Untranscribed Speech by Leveraging Spoken Term Detection and Self-supervised Learning of Speech Representations </p>
<p align="left" style="color:blue"> By Nay San, Martijn Bartelds and Dan Jurafsky</p>
<p align="left">
We summarise findings from our recent work showing that a large self-supervised model trained only on English speech provides a noise-robust and speaker-invariant feature extraction method that can be used for a speech information retrieval task with unrelated low resource target languages.  A qualitative error analysis also revealed that the majority of the retrieval errors could be attributed to the differences in phonological inventories between English and the evaluation languages.  With a longer-term aim of leveraging typological information to better adapt such models for the target languages, we also report on work in progress which examines the phonetic information encoded in these representations.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/FXYP5hoXP8o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1bA41137xS" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-28" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/28.pdf" class="button small">Paper</a></p>
       </div>
      </div>
    </div>


<br/> 
<h3 style="font-size:21px"><font color="green">&nbsp;Linguistic Typology Module&nbsp;</font></h3><br/>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 1 &nbsp;&nbsp;Starts: <font data-time="2021-06-09 20:30">08:30 PM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-09 22:30">10:30 PM</font> <br/> &nbsp;&nbsp;&nbsp; (Moderators: Ryan Cotterell, Eleanor Chodroff)</p>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 2 &nbsp;&nbsp;Starts: <font data-time="2021-06-10 08:00">08:00 AM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-10 10:00">10:00 AM</font> <br/> &nbsp;&nbsp;&nbsp; (Moderators: Gabriella Lapesa)</p>
 <p style="font-size:18px"> &nbsp;&nbsp;&nbsp; Registration: <a href="https://forms.gle/bAL1KXPDWHjMx7D66">https://forms.gle/bAL1KXPDWHjMx7D66</a> </p>
<br/>

<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#ktalk-ling-typology">Keynote Talk by Claire Bowern: Universals: Some key questions for phonetic typology (1 hour)</a>
        </h4>
      </div>
      <div id="ktalk-ling-typology" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">>
<p align="left" style="color:red;font-size:16px">Keynote Talk by Claire Bowern: Universals: Some key questions for phonetic typology</p>
<p align="left">
<img src="workshops/2021/keynotes/claire-bowern.jpeg" alt="Claire Bowern" style="height:110px;float:left;margin:9px"/>
Claire Bowern is Professor of linguistics at Yale University.
Claire is a historical linguist whose research is centered around language change and language documentation in Indigenous Australia. Since 2015 she has served as the vice president of the Endangered Language Fund. While her work touches many areas, the overarching question is how to characterize the nature of language change. Language change involves a complex interplay of universal properties of language acquisition and production and community-specific social factors; her research program looks at how to study this so we understand both the micro change(es) in progress and the macro change that leads to language families. She works with speakers of endangered languages, with archival sound and print materials, and she uses computational and phylogenetic methods. 
<br/>
The SIGTYP2021 theme of "Universals and Diversity" raises many interesting questions for comparative phonetics. In this talk, I unpack and discuss some of the theoretical background to how universal thinking in typology might apply to phonetic corpora, particularly for computational approaches to investigating speech across large-scale datasets. Because of the way that auditory language is produced, phonetics involves extensive interaction between psychological, neurological, physiological, social, linguistic, situational, and signals processing. That is, speech begins in the mind and brain, but is shaped by the body, and encodes linguistic and social meaning. Moreover, language is an evolutionary system, with universal properties shared by all such systems. Following discussion of universals and variation, I suggest some key questions that this approach allows, around phylogenetics of speech, marking of social cues, and the role of phonological constrast in structuring phonetic variation.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/XAc0F1cud_w" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  align="center"><a href="workshops/2021/keynotes/claire-bowern.pdf" class="button small">Slides</a>&nbsp;&nbsp;<a href="https://www.bilibili.com/video/BV1YU4y1V76E" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-keynote-claire" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://ling.yale.edu/people/claire-bowern" class="button small">Claire's Website</a></p>
       </div>
      </div>
    </div>



 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-1">OTEANN: Estimating the Transparency of Orthographies with an Artificial Neural Network (15 min)</a>
        </h4>
      </div>
      <div id="paper-1" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">OTEANN: Estimating the Transparency of Orthographies with an Artificial Neural Network</p>
<p align="left" style="color:blue"> By Xavier Marjou</p>
<p align="left">
To transcribe spoken language to written medium, most alphabets enable an unambiguous sound-to-letter rule. However, some writing systems have distanced themselves from this simple concept and little work exists in Natural Language Processing (NLP) on measuring such distance. In this study, we use an Artificial Neural Network (ANN) model to evaluate the transparency between written words and their pronunciation, hence its name Orthographic Transparency Estimation with an ANN (OTEANN). Based on datasets derived from Wikimedia dictionaries, we trained and tested this model to score the percentage of false predictions in phoneme-to-grapheme and grapheme-to-phoneme translation tasks. The scores obtained on 17 orthographies were in line with the estimations of other studies. Interestingly, the model also provided insight into typical mistakes made by learners who only consider the phonemic rule in reading and writing.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/tQ1V3yLgfhk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1eV411x7kf" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-1" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.1.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-21">Modeling Linguistic Typology - A Probabilistic Graphical Models Approach, Extended Abstract (15 min)</a>
        </h4>
      </div>
      <div id="paper-21" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:red;font-size:16px">Modeling Linguistic Typology - A Probabilistic Graphical Models Approach</p>
<p align="left" style="color:blue"> By Xia Lu</p>
<p>
In this paper, we propose to use probabilistic graphical models as a new theoretical and computational framework  to  study  linguistic  typology.   The  graphical  structure  of  such  a  model  represents  a  meta-language that consists of linguistic variables and the relationships between them while the parameters associated with each variable can be used to infer the strength of the relationships between the variables. Such models can also be used to predict feature values of new languages. Besides providing better solutions to existing problems in linguistic typology such a framework opens up to many new research topics that can help us to gain further insights into linguistic typology.</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-21" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/21.pdf" class="button small">Paper</a></p>
       </div>
      </div>
    </div>


 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-4">On the Universality of Lexical Concepts, Extended Abstract (15 min)</a>
        </h4>
      </div>
      <div id="paper-4" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">On the Universality of Lexical Concepts</p>
<p align="left" style="color:blue"> By Bradley Hauer and Grzegorz Kondrak</p>
<p align="left">
We posit that lexicalized concepts are universal, and thus can be annotated cross-linguistically in parallel corpora. This is one of the implications of a novel theory that formalizes the relationship between words and senses in both monolingual and multilingual settings. The theory is based on a unifying treatment ofthe notions of synonymy and translational equivalence as different aspects of the relation of sameness of meaning within and across languages.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Ha5c7NH8lEk" title="YouTube video player" frameborder="0" style="display: block; margin: auto;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  align="center"><a href="https://www.bilibili.com/video/BV1Ao4y1y7Bx" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-4" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/4.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-9">Subword Geometry: Picturing Word Shapes, Extended Abstract (15 min)</a>
        </h4>
      </div>
      <div id="paper-9" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Subword Geometry: Picturing Word Shapes</p>
<p align="left" style="color:blue"> By Olga Sozinova and Tanja Samardzic</p>
<p align="left" >
In this work in progress, we are investigating the structural properties of subwords in 20 languages by extracting word shapes, i.e. sequences of subword lengths.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/jy6931sVOxE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  align="center"><a href="https://www.bilibili.com/video/BV1m44y1z7jp" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-9" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/9.pdf"  class="button small">Paper</a></p>

       </div>
      </div>
    </div>


 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-20">Plugins for Structurally Varied Languages in XMG Framework, Extended Abstract (no video)</a>
        </h4>
      </div>
      <div id="paper-20" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:red;font-size:16px">Plugins for Structurally Varied Languages in XMG Framework</p>
<p align="left" style="color:blue"> By Valeria Generalova</p>
<p>
This paper aims to suggest an XMG-based design of metagrammatical classes storing language-specific information on a multilingual grammar engineering project.  It also presents a method of reusing the information from WALS. The principal claim is the hierarchy of features and the modular architecture of feature structures.
</p>
<p align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-20" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="workshops/2021/abstracts/20.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<br/>
<h3 style="font-size:21px"><font color="blue">&nbsp;Shared Task Module&nbsp;</font></h3><br/>
<p class="modtime" style="font-size:18px">&nbsp;&nbsp;Session 1 &nbsp;&nbsp;Starts: <font data-time="2021-06-10 10:00">10:00 AM</font> &nbsp;&nbsp;&nbsp; Ends: <font data-time="2021-06-10 11:00">11:00 AM</font> <br/> &nbsp;&nbsp;&nbsp; (Moderators: Elizabeth Salesky, Sabrina Mielke, Badr Abdullah)</p>
 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#shared-task">Shared Task 2021 Overview (15 min)</a>
        </h4>
      </div>
      <div id="shared-task" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Shared Task 2021 Overview</p>
<p align="left" style="color:blue"> By Elizabeth Salesky, Badr Abdullah, and Sabrina Mielke</p>
<p align="left">
While language identification is a fundamental speech and language processing task, for many languages and language families it remains a challenging task. For many low-resource and endangered languages this is in part due to resource availability: where larger datasets exist, they may be single-speaker or have different domains than desired application scenarios, demanding a need for domain and speaker-invariant language identification systems. This year’s shared task on robust spoken language identification sought to investigate just this scenario: systems were to be trained on largely single-speaker speech from one domain, but evaluated on data in other domains recorded from speakers under different recording circumstances, mimicking realistic low-resource scenarios. We see that domain and speaker mismatch proves very challenging for current methods which can perform above 95% accuracy in-domain, which domain adaptation can address to some degree, but that these conditions merit further investigation to make spoken language identification accessible in many scenarios.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Cvz6c-f9B_4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  align="center"><a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-module-shared-task" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.11.pdf"  class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-24">Language ID Prediction from Speech Using Self-Attentive Pooling and 1D-Convolutions (15 min)</a>
        </h4>
      </div>
      <div id="paper-24" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Language ID Prediction from Speech Using Self-Attentive Pooling and 1D-Convolutions</p>
<p align="left" style="color:blue"> By Roman Bedyakin and Nikolay Mikhaylovskiy</p>
<p align="left">
This memo describes NTR-TSU submission for SIGTYP 2021 Shared Task on predicting language IDs from speech. Spoken Language Identification (LID) is an important step in a multilingual Automated Speech Recognition (ASR) system pipeline. For many low-resource and endangered languages, only single-speaker recordings may be available, demanding a need for domain and speaker-invariant language ID systems. In this memo, we show that a convolutional neural network with a Self-Attentive Pooling layer shows promising results for the language identification task.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/C_eBc01pC7E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV1sQ4y1d7ZE" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-24" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.12.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-29">A ResNet-50-based Convolutional Neural Network Model for Language ID Identification from Speech Recordings (15 min)</a>
        </h4>
      </div>
      <div id="paper-29" class="panel-collapse collapse">
        <div class="panel-body"  style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">A ResNet-50-based Convolutional Neural Network Model for Language ID Identification from Speech Recordings</p>
<p align="left" style="color:blue"> By Giuseppe G.A. Celano</p>
<p align="left">
This paper describes the model built for the SIGTYP 2021 Shared Task aimed at identifying 18 typologically different languages from speech recordings. Mel-frequency cepstral coefficients derived from audio files are transformed into spectrograms, which are then fed into a ResNet-50-based CNN architecture. The final model achieved validation and test accuracies of 0.73 and 0.53, respectively.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/y4u1WlQS4WM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="https://www.bilibili.com/video/BV165411M72A" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-29" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.13.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#paper-31">Anlirika: An LSTM–CNN Flow Twister for Spoken Language Identification (15 min)</a>
        </h4>
      </div>
      <div id="paper-31" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:red;font-size:16px">Anlirika: An LSTM–CNN Flow Twister for Spoken Language Identification</p>
<p align="left" style="color:blue"> By Andreas Scherbakov, Liam Whittle, Ritesh Kumar, Siddharth Singh, Matthew Coleman and Ekaterina Vylomova</p>
<p align="left">
The paper presents Anlirika’s submission to SIGTYP 2021 Shared Task on Robust Spoken Language Identification. The task aims at building a robust system that generalizes well across different domains and speakers. The training data is limited to a single domain only with predominantly single speaker per language while the validation and test data samples are derived from diverse dataset and multiple speakers. We experiment with a neural system comprising a combination of dense, convolutional, and recurrent layers that are designed to perform better generalization and obtain speaker-invariant representations. We demonstrate that the task in its constrained form (without making use of external data or augmentation the train set with samples from the validation set) is still challenging. Our best system trained on the data augmented with validation samples achieves 29.9% accuracy on the test data.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/AkZBL83_Bck" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2021/slides/AnLirika.pdf" class="button small">Slides</a>&nbsp;&nbsp;<a href="https://TBA" class="button small">BiliBili</a>&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/ws3-paper-31" class="button small">RocketChat</a>&nbsp;&nbsp;<a href="https://aclanthology.org/2021.sigtyp-1.14.pdf" class="button small">Paper</a></p>

       </div>
      </div>
    </div>

<br/>
<h3 style="font-size:21px"><font color="cyan">&nbsp;Socialization Module&nbsp;</font></h3><br/>
 <div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse30" style="font-size:18px">Between Sessions: Linguistic Trivia Games</a>
        </h4>
      </div>
      <div id="collapse30" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By SIGTYP2021 Organizing Committee</p>
<p>
TBA
</p>

   </div>
      </div>
    </div>


<div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse32" style="font-size:18px">Between Sessions: Open Mic Discussion</a>
        </h4>
      </div>
      <div id="collapse32" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By SIGTYP2021 Organizing Committee</p>
<p>
TBA
</p>

</div>
      </div>
    </div>



<br/>

<br/>
  <div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse31" style="font-size:18px">Closing Session</a>
        </h4>
      </div>
      <div id="collapse31" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By SIGTYP2021 Organizing Committee</p>
<p>
Closing Remarks and SIGTYP 2022 Announcement! 
</p>

</div>
      </div>
    </div>

</div>
<br/>
<br/>


<!--p style="font-size:18px">You may also <a href="http://">Read it in PDF</a></p-->

						</section>
					</div>
					
				</div>
			</div>
		</div>
	
	<!-- Copyright -->
		<div id="copyright">
			<div class="container">
				Contact Email: <a href="mailto:sigtyp AT gmail DOT com"> sigtyp AT gmail DOT com </a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  WebMaster: <a href="http://kat.academy">EKATERINA VYLOMOVA</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Design: <a href="http://templated.co">TEMPLATED</a>
			</div>
		</div>
 <script>
        if (location.hash !== null && location.hash !== "") {
            $(location.hash + ".collapse").collapse("show");
        }
    </script>

	</body>
</html>
