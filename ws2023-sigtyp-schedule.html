<!DOCTYPE HTML>
<!--
	Imagination by TEMPLATED
    templated.co @templatedco
    Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>SIGTYP -- Workshop 2023 Schedule</title>
		<link rel="shortcut icon" type="image/x-icon" href="images/favicon.ico" />
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="sigtyp,sigtyp2022,naacl,emnlp,workshop,typology,linguistics,multilinguality" />
		<link href='http://fonts.googleapis.com/css?family=Raleway:400,100,200,300,500,600,700,800,900' rel='stylesheet' type='text/css'>
		<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  		<!--script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script-->
  		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/skel-panels.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel-noscript.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-desktop.css" />
		</noscript>

		


	</head>
	<body>

	<div id="header-wrapper">

		<!-- Header -->
			<div id="header">
				<div class="container">
						
					<!-- Logo -->
						<div id="logo">
							<a href="index.html"><img src="images/sigtyp1.jpg"  style="width:70px" alt="SIGTYP"></a>
							<!--h1><a href="#"><font color=red>S</font>IG<font color=red>T</font>YP</a></h1-->
						</div>
					
					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Homepage</a></li>
								<li><a href="constitution.html">Constitution</a></li>
								<li><a href="members.html">Members</a></li>
								<li class="active"><a href="workshop.html">Workshop</a></li>
								<li><a href="lectures.html">Lectures</a></li>
								<li><a href="blog.html">Blog</a></li>
							</ul>
						</nav>
	
				</div>
			</div>
		<!-- Header -->

		<!-- Banner -->
			<div id="banner">
				<div class="container">
	
					<section>
						<!--span class="fa fa-cubes"></span-->
						<header>
							<h2 > </h2>
							<h2 > </h2>
<h2 > </h2>
							<span class="byline"> </span>
						</header>
						<!--a href="#" class="button medium">Fusce ultrices fringilla</a-->
					</section>	
				</div>
			</div>
		<!-- /Banner -->
and
	</div>

	<!-- Main -->
		<div id="main">
			<div class="container">
				<div class="row">
		
									
					<div class="container">
						<section>
							<header>
							
							<h2>  <font color="red">S</font><font color="yellow">I</font><font color="green">G</font><font color="brown">T</font><font color="blue">Y</font><font color="purple">P</font>2023 — MAY,6th — Dubrovnik/Hybrid</h2> </header>
<hr/>
<p style="font-size:16px">We kindly invite <strong>everyone</strong> to join the virtual part of SIGTYP 2023! Below you may explore papers, slides, and recorded talks. All discussions are happening in <a href="https://sigtyp.inf.ethz.ch/channel/general">our Rocket.Chat</a>. Each paper is provided with its own discussion channel. On <a href="https://sigtyp.inf.ethz.ch/channel/general">our Rocket.Chat</a> and <a href="https://groups.google.com/u/1/g/sigtyp">Google Group</a> you may also find a single Zoom link that will be used during the day of the workshop.
<br/>
SIGTYP2023 Proceedings are now available <a href="workshops/2023/sigtyp/papers/SIGTYP2023_proceedings.pdf">here</a>.

</p>

<hr style="border-top: dotted 2px;"/>									
<p style="font-size:18px">

<strong>Time zone: Croatia/Dubrovnik</strong>
							</p>
<!--div class="container"-->
  <!--h3 style="font-size:21px"><font color="red">&#10043;</font>&nbsp;THESES&nbsp;<font color="red">&#10043;</font>&nbsp;</h3><br/-->
  <div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse1" style="font-size:18px">8:50 &ndash; 9:00  Opening Session</a>
        </h4>
      </div>
      <div id="collapse1" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By SIGTYP2023 Organizing Committee</p>
<p align="left">
Opening remarks: the SIGTYP 2023 workshop, SIGTYP  development and MRL! <!--Slides are available <a href="workshops/2023/sigtyp/slides/SIGTYP_2022_opening_session.pdf">here</a-->
</p>

 <!--iframe width="560" height="315" src="https://www.youtube.com/embed/TBA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe-->

</div>
      </div>
    </div>
<br/> 

<h3 style="font-size:21px"><font color="green">&#10043;</font>&nbsp;Keynote Talk&nbsp;<font color="green">&#10043;</font></h3><br/>
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse2">9:00 &ndash; 9:50 Ella Rabinovich (Keynote): Semantic Typology in Action: Identification of Semantic Infelicities in L2 English Indefinite Pronouns</a>
        </h4>
      </div>
      <div id="collapse2" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left">
<img src="workshops/2023/sigtyp/speakers/ella.png" alt="Ella Rabinovich" style="height:110px;float:left;margin:9px"/>
Semantic typologists have proposed (and empirically supported, across many domains) that the more two concepts are colexified across languages, the more similar those two concepts are. As such, crosslinguistic patterns of colexification can be used to deduce pairwise similarity among concepts, yielding a universal semantic similarity space for a domain (e.g., Berlin and Kay, 1969; Levinson et al., 2003). In this talk she will show that insights from semantic typology in the domain of indefinite pronouns are suggestive of challenges in their second-language (L2) English acquisition. She will also present a corpus-based analysis of L2 English indefinite pronouns and results of an automatic approach to detecting L2 semantic infelicities, stemming from these challenges.
<br/>

Bio: Ella is a researcher in the IBM Research Labs in Haifa, Israel. Her research focuses on computational approaches to the study of various aspects of bilingualism. She explores the unique properties of translated texts and productions of advanced non-native speakers, covering a wide range of syntactic and lexical phenomena and applying state-of-the-art (supervised and unsupervised) machine learning and natural language processing techniques. Additional topics she is interested in include computational social science, informational retrieval, argumentation mining.
She completed my Ph.D. at the Department of Computer Science, University of Haifa (Israel) under the supervision of Prof. Shuly Wintner.
</p>
 <!--iframe width="560" height="315" src="https://wTBA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe-->
<p align="center"><a href="workshops/2023/sigtyp/slides/TBA" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="https://www.int.mta.ac.il/faculty-members/Dr.-Ella-Rabinovich" class="button small">Ella's Website</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-kt1" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

	</div>
      </div>
    </div>
  <br/>


<h3 style="font-size:21px"><font color="purple">&#10043;</font>&nbsp;Cross-Lingual Transfer &nbsp;<font color="purple">&#10043;</font></h3><br/>

   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse3">09:50 &ndash; 10:00 Identifying the Correlation Between Language Distance and Cross-Lingual Transfer
    in a Multilingual Representation Space</a>
        </h4>
      </div>
      <div id="collapse3" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Fred Philippy, Siwen Guo and Shohreh Haddadan</p>
<p align="left">
Prior research has investigated the impact of various linguistic features
    on cross-lingual transfer performance. In this study, we investigate the manner
    in which this effect can be mapped onto the representation space. While past studies
    have focused on the impact on cross-lingual alignment in multilingual language
    models during fine-tuning, this study examines the absolute evolution of the respective
    language representation spaces produced by MLLMs. We place a specific emphasis
    on the role of linguistic characteristics and investigate their inter-correlation
    with the impact on representation spaces and cross-lingual transfer performance.
    Additionally, this paper provides preliminary evidence of how these findings can
    be leveraged to enhance transfer to linguistically distant languages.</p>
   <iframe width="560" height="315" src="https://www.youtube.com/embed/ltP1zLbhNDY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/language-distance.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/3_identifying_the_correlation_be.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p3" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
       </div>
      </div>
    </div>



   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse4">10:00 &ndash; 10:10 Gradual Language Model Adaptation Using Fine-Grained Typology</a>
        </h4>
      </div>
      <div id="collapse4" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Marcell Richard Fekete and Johannes Bjerva</p>
<p align="left">
Transformer-based language models (LMs) offer superior performance in
    a wide range of NLP tasks compared to previous paradigms. However, the vast majority
    of the world's languages do not have adequate training data available for monolingual
    LMs (Joshi et al., 2020). While the use of multilingual LMs might address this
    data imbalance, there is evidence that multilingual LMs struggle when it comes
    to model adaptation to to resource-poor languages (Wu and Dredze, 2020), or to
    languages which have typological characteristics unseen by the LM (Üstün et al.,
    2022). Other approaches aim to adapt monolingual LMs to resource-poor languages
    that are related to the model language. However, there are conflicting findings
    regarding whether language relatedness correlates with successful adaptation (de
    Vries et al., 2021), or not (Ács et al., 2021). With gradual LM adaptation, our
    approach presented in this extended abstract, we add to the research direction
    of monolingual LM adaptation. Instead of direct adaptation to a target language,
    we propose adaptation in stages, first adapting to one or more intermediate languages
    before the final adaptation step. Inspired by principles of curriculum learning
    (Bengio et al., 2009), we search for an ideal ordering of languages that can result
    in improved LM performance on the target language. We follow evidence that typological
    similarity might correlate with the success of cross-lingual transfer (Pires et
    al., 2019; Üstün et al., 2022; de Vries et al., 2021) as we believe the success
    of this transfer is essential for successful model adaptation. Thus we order languages
    based on their relative typological similarity between them. In our approach,
    we quantify typological similarity using structural vectors as derived from counts
    of dependency links (Bjerva et al., 2019), as such fine-grained measures can give
    a more accurate picture of the typological characteristics of languages (Ponti
    et al., 2019). We believe that gradual LM adaptation may lead to improved LM performance
    on a range of resource-poor languages and typologically diverse languages. Additionally,
    it enables future research to evaluate the correlation between the success of
    cross-lingual transfer and various typological similarity measures.</p>
  <!--iframe width="560" height="315" src="https://www.youtube.com/embed/TBA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe-->
<p align="center"><a href="workshops/2023/sigtyp/slides/TBA" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/16_gradual_language_model_adaptat.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p16" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>

   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse41">10:10 &ndash; 10:20 Cross-Lingual Transfer Learning with Persian</a>
        </h4>
      </div>
      <div id="collapse41" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Sepideh Mollanorozy, Marc Tanti and Malvina Nissim</p>
<p align="left">
The success of cross-lingual transfer learning for POS tagging has been
    shown to be strongly dependent, among other factors, on the (typological and/or
    genetic) similarity of the low-resource language used for testing and the language(s)
    used in pre-training or to fine-tune the model. We further unpack this finding
    in two directions by zooming in on a single language, namely Persian. First, still
    focusing on POS tagging we run an in-depth analysis of the behaviour of Persian
    with respect to closely related languages and languages that appear to benefit
    from cross-lingual transfer with Persian. To do so, we also use the World Atlas
    of Language Structures to determine which properties are shared between Persian
    and other languages included in the experiments. Based on our results, Persian
    seems to be a reasonable potential language for Kurmanji and Tagalog low-resource
    languages for other tasks as well. Second, we test whether previous findings also
    hold on a task other than POS tagging to pull apart the benefit of language similarity
    and the specific task for which such benefit has been shown to hold. We gather
    sentiment analysis datasets for 31 target languages and through a series of cross-lingual
    experiments analyse which languages most benefit from Persian as the source. The
    set of languages that benefit from Persian had very little overlap across the
    two tasks, suggesting a strong task-dependent component in the usefulness of language
    similarity in cross-lingual transfer.</p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/SpMzbE4s43A" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/transfer-learning-with-persian.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/17_cross_lingual_transfer_learnin.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p17" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>

   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse42">10:20 &ndash; 10:35 Cross-Lingual Transfer of Cognitive Complexity (Findings)</a>
        </h4>
      </div>
      <div id="collapse42" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Charlotte Pouw, Nora Hollenstein and Lisa Beinborn</p>
<p align="left">
When humans read a text, their eye movements are influenced by the structural complexity of the input sentences. This cognitive phenomenon holds across languages and recent studies indicate that multilingual language models utilize structural similarities between languages to facilitate cross-lingual transfer. We use sentence-level eye-tracking patterns as a cognitive indicator for structural complexity and show that the multilingual model XLM-RoBERTa can successfully predict varied patterns for 13 typologically diverse languages, despite being fine-tuned only on English data. We quantify the sensitivity of the model to structural complexity and distinguish a range of complexity characteristics. Our results indicate that the model develops a meaningful bias towards sentence length but also integrates cross-lingual differences. We conduct a control experiment with randomized word order and find that the model seems to additionally capture more complex structural information. </p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/gJqFjzQ2K0s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/cognitive-complexity.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/EACL_Cross_lingual_Transfer_of_Linguistic_Complexity.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-findings-1" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>

<br/>

    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse5">10:35 &ndash; 11:15 Break</a>
        </h4>
      </div>
      <div id="collapse5" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left">
Coffee break, chats, linguistic trivia
</p>
       </div>
      </div>
    </div>


  <br/>
  <h3 style="font-size:21px"><font color="blue">&#10043;</font>&nbsp;Multilinguality&nbsp;<font color="blue">&#10043;</font></h3><br/>

   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse6">11:15 &ndash; 11:30 Does Transliteration Help Multilingual Language Modeling (Findings)</a>
        </h4>
      </div>
      <div id="collapse6" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Ibraheem Muhammad Moosa, Mahmud Elahi Akhter and Ashfia Binte Habib</p>
<p align="left">
As there is a scarcity of large representative corpora for most languages, it is important for Multilingual Language Models (MLLM) to extract the most out of existing corpora. In this regard, script diversity presents a challenge to MLLMs by reducing lexical overlap among closely related languages. Therefore, transliterating closely related languages that use different writing scripts to a common script may improve the downstream task performance of MLLMs. In this paper, we pretrain two ALBERT models to empirically measure the effect of transliteration on MLLMs. We specifically focus on the Indo-Aryan language family, which has the highest script diversity in the world. Afterward, we evaluate our models on the IndicGLUE benchmark. We perform Mann-Whitney U test to rigorously verify whether the effect of transliteration is significant or not. We find that transliteration benefits the low-resource languages without negatively affecting the comparatively high-resource languages. We also measure the cross-lingual representation similarity (CLRS) of the models using centered kernel alignment (CKA) on parallel sentences of eight languages from the FLORES-101 dataset. We find that the hidden representations of the transliteration-based model have higher and more stable CLRS scores. Our code is available at Github and Hugging Face Hub.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Uhk2FpaFh_M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/does-transliteration-help.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/EACL_Does_Transliteration_Help_Multilingual_Language_Modeling.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-findings2" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>



   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse7">11:30 &ndash; 11:40 Multilingual BERT has an Accent: Evaluating English Influences on Fluency in
Multilingual Models</a>
        </h4>
      </div>
      <div id="collapse7" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Isabel Papadimitriou, Kezia Lopez and Dan Jurafsky</p>
<p align="left">
While multilingual language models can improve NLP performance on low-resource
    languages by leveraging higher-resource languages, they also reduce average performance
    on all languages (the ''curse of multilinguality'').  Here we show another problem
    with multilingual models: grammatical structures in higher-resource languages
    bleed into lower-resource languages, a phenomenon we call  grammatical structure
    bias.  We show this bias via a novel method  for comparing the fluency of multilingual
    models to the fluency of monolingual Spanish and Greek models: testing their preference
    for two carefully-chosen variable grammatical structures (optional pronoun-drop
    in Spanish and optional Subject-Verb ordering in Greek). We find that multilingual
    BERT is biased toward the English-like setting (explicit pronouns and Subject-Verb-Object
    ordering) and against the default Spanish and Gerek settings, as compared to our
    monolingual control language model.  With our case studies, we hope to bring to
    light the fine-grained ways in which multilingual models can be biased, and encourage
    more linguistically-aware fluency evaluation.</p>
   <!--iframe width="560" height="315" src="https://www.youtube.com/embed/TBA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe-->
<p align="center"><a href="workshops/2023/sigtyp/slides/TBA" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/5_multilingual_bert_has_an_accen.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p5" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>


       </div>
      </div>
    </div>
    
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse8">11:40 &ndash; 11:55 The Denglisch Corpus of German-English Code-Switching</a>
        </h4>
      </div>
      <div id="collapse8" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Doreen Osmelak and Shuly Wintner</p>
<p align="left"> When multilingual speakers involve in a conversation they inevitably introduce
    code-switching (CS), i.e., mixing of more than one language between and within
    utterances. CS is still an understudied phenomenon, especially in the written
    medium, and relatively few computational resources for studying it are available.
    We describe a corpus of German-English code-switching in social media interactions.
    We focus on some challenges in annotating CS, especially due to words whose language
    ID cannot be easily determined. We introduce a novel schema for such word-level
    annotation, with which we manually annotated a subset of the corpus. We then trained
    classifiers to predict and identify switches, and applied them to the remainder
    of the corpus. Thereby, we created a large scale corpus of German-English mixed
    utterances with precise indications of CS points.</p>
 <iframe width="560" height="315" src="https://www.youtube.com/embed/VXYr2acskiQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/the-denglisch-corpus.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/6_the_denglisch_corpus_of_german.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p6" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>


       </div>
      </div>
    </div>
   
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse9">11:55 &ndash; 12:10 Trimming Phonetic Alignments Improves the Inference of Sound Correspondence
Patterns from Multilingual Wordlists</a>
        </h4>
      </div>
      <div id="collapse9" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Frederic Blum and Johann-Mattis List</p>
<p align="left"> Sound correspondence patterns form the basis of cognate detection and
    phonological reconstruction in historical language comparison. Methods for the
    automatic inference of correspondence patterns from phonetically aligned cognate
    sets have been proposed, but their application to multilingual wordlists requires
    extremely well annotated datasets. Since annotation is tedious and time consuming,
    it would be desirable to find ways to improve aligned cognate data automatically.
    Taking inspiration from trimming techniques in evolutionary biology, which improve
    alignments by excluding problematic sites, we propose a workflow that trims phonetic
    alignments in comparative linguistics prior to the inference of correspondence
    patterns. Testing these techniques on a large standardized collection of ten datasets
    with expert annotations from different language families, we find that the best
    trimming technique substantially improves the overall consistency of the alignments,
    showing a clear increase in the proportion of frequent correspondence patterns
    and words exhibiting regular cognate relations.</p>
 <iframe width="560" height="315" src="https://www.youtube.com/embed/XPeKh7ucPas" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/trimming-phonetic-alignments.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/8_trimming_phonetic_alignments_i.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p8" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
       </div>
      </div>
    </div>
  
     <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse10">12:10 &ndash; 12:20 On the Nature of Discrete Speech Representations in Multilingual Self-supervised
Models</a>
        </h4>
      </div>
      <div id="collapse10" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Badr M. Abdullah, Mohammed Maqsood Shaik and Dietrich Klakow</p>
<p align="left">Self-supervision has emerged as an effective paradigm for learning representations
    of spoken language from raw audio without explicit labels or transcriptions. Self-supervised
    speech models, such as wav2vec 2.0 (Baevski et al., 2020) and HuBERT (Hsu et al.,
    2021), have shown significant promise in improving the performance across different
    speech processing tasks. One of the main advantages of self-supervised speech
    models is that they can be pre-trained on a large sample of languages (Conneau
    et al., 2020; Babu et al.,2022), which facilitates cross-lingual transfer for
    low-resource languages (San et al., 2021). State-of-the-art self-supervised speech
    models include a quantization module that transforms the continuous acoustic input
    into a sequence of discrete units. One of the key questions in this area is whether
    the discrete representations learned via self-supervision are language-specific
    or language-universal. In other words, we ask: do the discrete units learned by
    a multilingual speech model represent the same speech sounds across languages
    or do they differ based on the specific language being spoken? From the practical
    perspective, this question has important implications for the development of speech
    models that can generalize across languages, particularly for low-resource languages.
    Furthermore, examining the level of linguistic abstraction in speech models that
    lack symbolic supervision is also relevant to the field of human language acquisition
    (Dupoux, 2018). </p>
 <iframe width="560" height="315" src="https://www.youtube.com/embed/ab58wO4B0wM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/discrete-speech-representations.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/On_the_Nature_ of_Discrete_Speech_Representations_in_Multilingual_Self-supervised_Models.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p20" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse101">12:20 &ndash; 12:30 You Can Have Your Data and Balance It Too: Towards Balanced and Efficient
Multilingual Models</a>
        </h4>
      </div>
      <div id="collapse101" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Tomasz Limisiewicz, Dan Malkin and Gabriel Stanovsky</p>
<p align="left">Multilingual models have been widely used for the cross-lingual transfer
    to low-resource languages. However, the performance on these languages is hindered
    by their under-representation in the pretraining data. To alleviate this problem,
    we propose a novel multilingual training technique based on teacher-student knowledge
    distillation. In this setting, we utilize monolingual teacher models optimized
    for their language. We use those teachers along with balanced (sub-sampled) data
    to distill the teachers' knowledge into a single multilingual student. Our method
    outperforms standard training methods in low-resource languages and retains performance
    on high-resource languages while using the same amount of data. If applied widely,
    our approach can increase the representation of low-resource languages in NLP
    systems.</p>
 <iframe width="560" height="315" src="https://www.youtube.com/embed/LWx3rARgm_4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/balanced-multilingual.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/1_you_can_have_your_data_and_bal.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p1" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse10002">12:30 &ndash; 12:45 Evaluating the Diversity, Equity and Inclusion of NLP Technology: A Case Study
for Indian Languages (Findings)</a>
        </h4>
      </div>
      <div id="collapse10002" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Simran Khanuja, Sebastian Ruder and Partha Talukdar</p>
<p align="left">In order for NLP technology to be widely applicable, fair, and useful, it needs to serve a diverse set of speakers across the world's languages, be equitable, i.e., not unduly biased towards any particular language, and be inclusive of all users, particularly in low-resource settings where compute constraints are common. In this paper, we propose an evaluation paradigm that assesses NLP technologies across all three dimensions. While diversity and inclusion have received attention in recent literature, equity is currently unexplored. We propose to address this gap using the Gini coefficient, a well-established metric used for estimating societal wealth inequality. Using our paradigm, we highlight the distressed state of current technologies for Indian (IN) languages (a linguistically large and diverse set, with a varied speaker population), across all three dimensions. To improve upon these metrics, we demonstrate the importance of region-specific choices in model building and dataset creation, and more importantly, propose a novel, generalisable approach to optimal resource allocation during fine-tuning. Finally, we discuss steps to mitigate these biases and encourage the community to employ multi-faceted evaluation when building linguistically diverse and equitable technologies. </p>
 <iframe width="560" height="315" src="https://www.youtube.com/embed/Nm4FmU36rlA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/diversity-equity-inclusion-NLP.pptx" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/EACL_Evaluating_Diversity_Equity_Inclusion_of_NLP_Technology.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-findings3" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
       </div>
      </div>
    </div>


<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse1001">12:45 &ndash; 13:00 A Large-Scale Multilingual Study of Visual Constraints on Linguistic Selection of
Descriptions (Findings)</a>
        </h4>
      </div>
      <div id="collapse1001" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Uri Berger, Lea Frermann, Gabriel Stanovsky and Omri Abend</p>
<p align="left">We present a large, multilingual study into how vision constrains linguistic choice, covering four languages and five linguistic properties, such as verb transitivity or use of numerals. We propose a novel method that leverages existing corpora of images with captions written by native speakers, and apply it to nine corpora, comprising 600k images and 3M captions. We study the relation between visual input and linguistic choices by training classifiers to predict the probability of expressing a property from raw images, and find evidence supporting the claim that linguistic properties are constrained by visual context across languages. We complement this investigation with a corpus study, taking the test case of numerals. Specifically, we use existing annotations (number or type of objects) to investigate the effect of different visual conditions on the use of numeral expressions in captions, and show that similar patterns emerge across languages. Our methods and findings both confirm and extend existing research in the cognitive literature. We additionally discuss possible applications for language generation.  </p>
 <iframe width="560" height="315" src="https://www.youtube.com/embed/4yEi5ZslUcc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/TBA" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/EACL_A_Large_Scale_Multilingual_Study_of_Visual_Constraints_on_Linguistic_Selection_of_Descriptions.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-findings4" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
       </div>
      </div>
    </div>

<br/> 
<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse12">13:00 &ndash; 14:15 Lunch</a>
        </h4>
      </div>
      <div id="collapse12" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left">
Lunch, discussions, linguistic trivia
</p>
       </div>
      </div>
    </div>


<br/>
<h3 style="font-size:21px"><font color="brown">&#10043;</font>&nbsp;Keynote Talk&nbsp;<font color="brown">&#10043;</font></h3><br/>
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse201">14:15 &ndash; 15:05 Natalia Levshina (Keynote): A Corpus-based Typology of “Who did What to Whom”: Cross-linguistic Correlations and Causal Links </a>
        </h4>
      </div>
      <div id="collapse201" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left">
<img src="workshops/2023/sigtyp/speakers/natalia.jpg" alt="Natalia Levshina" style="height:110px;float:left;margin:9px"/>
Different languages use different linguistic cues to express “who did what to whom”, helping the addressee to identify Subject and Object. These cues include case marking, agreement, semantics, and word order. Previous research has revealed that different cues can be correlated (Greenberg 1966; Sinnemäki 2010; Levshina 2021). For example, some languages express the roles with case (Latin, Czech) and relatively flexible word order, while others (English, Mandarin) use rigid word order and have no nominal case makers. Some of the differences between the languages have been explained by sociolinguistic factors, such as population size and high proportion of L2 (non-native) users, which can lead to grammatical simplification – in particular, to loss of case (Lupyan & Dale 2010; McWhorter 2011; Trudgill 2011; Bentz & Winter 2013; Koplenig 2019). 	<br/>	 

The aim of my talk is to investigate the relations between the linguistic and sociolinguistic variables and confirm or refute the previous hypotheses about the typological correlations and causal links. To obtain the linguistic variables, I use typological databases, such as the World Atlas of Language Structures (WALS) by Dryer & Haspelmath (2013), and corpus data: large web-based corpora of online news (Goldhahn et al. 2012) annotated with Universal Dependencies; Universal Dependencies corpora (Zeman et al. 2022); the parallel corpus of Bible translations (Mayer & Cysouw 2014) and word order data inferred from this corpus (Östling 2015). These sources provide information about four variables that help to understand “who did what to whom”: 1) the entropy of Subject and Object order based on the probabilities of Subject-Object (SO) and Object-Subject (OS) orders in the corpora; 2) whether the forms of Subject and Object are the same or distinct thanks to case flagging; 3) the position of the lexical verb in a transitive clause: final or non-final, and 4) Mutual Information of the grammatical roles and lexemes, which approximates semantic tightness of a language (Hawkins 1986). To get the sociolinguistic data, I use the information about the population size and L2 speaker proportions from the Ethnologue database, as well as the datasets from Koplenig (2019) and Sinnemäki & Di Garbo (2018). The relationships between all these variables are studied with the help of correlational and causal analyses (Pearl 2000), which involve different types of generalized mixed models and the Fast Causal Inference algorithm (Zhang 2008). The genealogical and geographic dependencies between the languages are modelled as random effects in generalized mixed-effects models. 

<br/>
Bio: Natalia Levshina is a linguist working at the Max Planck Institute for Psycholinguistics in Nijmegen. Her main research interests are linguistic typology, corpora, cognitive and functional linguistics. After obtaining her PhD at the University of Leuven in 2011, she has worked in Jena, Marburg, Louvain-la-Neuve and Leipzig, where she got her habilitation qualification in 2019. She has recently published a book “Communicative Efficiency: Language structure and use” (Cambridge University Press, 2022), in which she formulates the main principles of communicatively efficient linguistic behaviour and shows how these principles can explain why human languages are the way they are. Natalia is also the author of a best-selling statistical manual “How to Do Linguistics with R” (Benjamins, 2015).     



 </p>
 <!--iframe width="560" height="315" src="https://www.youtube.com/embed/TBA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe-->
<p align="center"><a href="workshops/2023/sigtyp/slides/TBA" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="https://www.mpi.nl/people/levshina-natalia" class="button small">Natalia's Webpage</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-kt2" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
	</div>
      </div>
    </div>
  <br/>


<h3 style="font-size:21px"><font color="purple">&#10043;</font>&nbsp;Linguistic Complexity &nbsp;<font color="purple">&#10043;</font></h3><br/>

   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse300">15:05 &ndash; 15:20 Information-Theoretic Characterization of Vowel Harmony: A Cross-Linguistic
Study on Word Lists</a>
        </h4>
      </div>
      <div id="collapse300" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Julius Steuer, Johann-Mattis List, Badr M. Abdullah and Dietrich Klakow</p>
<p align="left">
We present a cross-linguistic study of vowel harmony that aims to quantifies
    this phenomenon using data-driven computational modeling. Concretely, we define
    an information-theoretic measure of harmonicity based on the predictability of
    vowels in a natural language lexicon, which we estimate using phoneme-level language
    models (PLMs). Prior quantitative studies have heavily relied on inflected word-forms
    in the analysis on vowel harmony. On the contrary, we train our models using cross-linguistically
    comparable lemma forms with little or no inflection, which enables us to cover
    more under-studied languages. Training data for our PLMs consists of word lists
    offering a maximum of 1000 entries per language. Despite the fact that the data
    we employ are substantially smaller than previously used corpora, our experiments
    demonstrate the neural PLMs capture vowel harmony patterns in a set of languages
    that exhibit this phenomenon. Our work also demonstrates that word lists are a
    valuable resource for typological research, and offers new possibilities for future
    studies on low-resource, under-studied languages.</p>
   <iframe width="560" height="315" src="https://www.youtube.com/embed/YqIfrz_vhbA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/vowel-harmony.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/18_information_theoretic_characte.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p18" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
       </div>
      </div>
    </div>



   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse400">15:20 &ndash; 15:35 A Crosslinguistic Database for Combinatorial and Semantic Properties of
Attitude Predicates</a>
        </h4>
      </div>
      <div id="collapse400" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Deniz Özyıldız, Ciyang Qing, Floris Roelofsen, Maribel Romero and Wataru
Uegaki</p>
<p align="left">
We introduce a cross-linguistic database for attitude predicates, which
    references their combinatorial (syntactic) and semantic properties. Our data allows
    assessment of cross-linguistic generalizations about attitude predicates as well
    as discovery of new typological/cross-linguistic patterns. This paper motivates
    empirical and theoretical issues that our database will help to address, the sample
    predicates and the properties that it references, as well as our design and methodological
    choices. Two case studies illustrate how the database can be used to assess validity
    of cross-linguistic generalizations.</p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/-1MHKcy6UK0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/properties-of-attitude-predicates.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/9_a_crosslinguistic_database_for.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p9" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>


   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse401">15:35 &ndash; 15:50 Revisiting Dependency Length and Intervener Complexity Minimisation on a
Parallel Corpus in 35 Languages</a>
        </h4>
      </div>
      <div id="collapse401" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Andrew Thomas Dyer</p>
<p align="left">
In this replication study of previous research into dependency length
    whether previous findings are upheld when controlling for variation in domain
    and sentence content between languages. We follow the approach of previous research
    minimisation (DLM), we pilot a new parallel multilingual parsed corpus to examine
    in comparing the dependency lengths of observed sentences in a multilingual corpus
    to a variety of baselines: permutations of the sentences, either random or according
    to some fixed schema. We go on to compare DLM with intervener complexity measure
    (ICM), an alternative measure of syntactic complexity. Our findings uphold both
    dependency length and intervener complexity minimisation in all languages under
    investigation. We also find a markedly lesser extent of dependency length minimisation
    in verb-final languages, and the same for intervener complexity measure. We conclude
    that dependency length and intervener complexity minimisation as universals are
    upheld when controlling for domain and content variation, but that further research
    is needed into the asymmetry between verb-final and other languages in this regard.</p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/xz66KSaOO3M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/revisiting-dependency-length.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/20_revisiting_dependency_length_a.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p20" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>
   
<br/>
<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse129">15:50 &ndash; 16:10 Break</a>
        </h4>
      </div>
      <div id="collapse129" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left">
Coffee, discussions
</p>
       </div>
      </div>
    </div>

<br/>
<h3 style="font-size:21px"><font color="orange">&#10043;</font>&nbsp;Shared Task Session&nbsp;<font color="orange">&#10043;</font></h3><br/>

    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse13">16:10 &ndash; 16:20 Findings of the SIGTYP 2023 Shared task on Cognate and Derivative Detection
For Low-Resourced Languages </a>
        </h4>
      </div>
      <div id="collapse13" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Priya Rani, Koustava Goswami, Adrian Doyle, Theodorus Fransen, Bernardo
Stearns and John P. McCrae</p>
<p align="left">This paper describes the structure and findings of the SIGTYP 2023 shared
    task on cognate and derivative detection for low-resourced languages, broken down
    into a supervised and unsupervised sub-task. The participants were asked to submit
    the test data’s final prediction. A total of nine teams registered for the shared
    task where seven teams registered for both sub-tasks. Only two participants ended
    up submitting system descriptions, with only one submitting systems for both sub-tasks.
    While all systems show a rather promising performance, all could be within the
    baseline score for the supervised sub-task. However, the system submitted for
    the unsupervised sub-task outperforms the baseline score.</p>
 <iframe width="560" height="315" src="https://www.youtube.com/embed/SONaLCGDXS4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/SIGTYP2023_Shared_task_findings-2023.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/22_Findings_of_the_SIGTYP_2023_Shared_task_on_Cognate_Detection_final.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-st" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>


    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse14">16:20 &ndash; 16:30 ÚFAL Submission for SIGTYP Supervised Cognate Detection Task</a>
        </h4>
      </div>
      <div id="collapse14" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Tomasz Limisiewicz</p>
<p align="left">In this work, I present ÚFAL submission for the supervised task of detecting
    cognates and derivatives. Cognates are word pairs in different languages sharing
    the origin in earlier attested forms in ancestral language, while derivatives
    come directly from another language. For the task, I developed gradient boosted
    tree classifier trained on linguistic and statistical features. The solution came
    first from two delivered systems with an 87% F1 score on the test split. This
    write-up gives an insight into the system and shows the importance of using linguistic
    features and character-level statistics for the task.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/iMhYGx9QC9U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/UFAL-Cognate-detection-presentation.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/23_Cognate_Detection_System_Description.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-st" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
       </div>
      </div>
    </div>


    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse15">16:30 &ndash; 16:40 CoToHiLi at SIGTYP 2023: Ensemble Models for Cognate and Derivative Words
Detection </a>
        </h4>
      </div>
      <div id="collapse15" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Liviu P. Dinu, Ioan-Bogdan Iordache and Ana Sabina Uban</p>
<p align="left">The identification of cognates and derivatives is a fundamental process
    in historical linguistics, on which any further research is based. In this paper
    we present our contribution to the SIGTYP 2023 Shared Task on cognate and derivative
    detection. We propose a multi-lingual solution based on features extracted from
    the alignment of the orthographic and phonetic representations of the words.
</p>
<!--iframe width="560" height="315" src="https://www.youtube.com/embed/TBA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe-->
<p align="center"><a href="workshops/2023/sigtyp/TBA" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/24_CoToHiLi-Sigtyp2023.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-st" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
       </div>
      </div>
    </div>

<br/> 
<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse18">16:40 &ndash; 16:45 Break</a>
        </h4>
      </div>
      <div id="collapse18" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left">
Coffee break, discussions, etc.
</p>
       </div>
      </div>
    </div>

<br/> 
<h3 style="font-size:21px"><font color="red">&#10043;</font>&nbsp;Syntax and Morphology&nbsp;<font color="red">&#10043;</font></h3><br/>



  <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse20">16:45 &ndash; 16:55 Grambank’s Typological Advances Support Computational Research on Diverse
Languages</a>
        </h4>
      </div>
      <div id="collapse20" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Hannah J. Haynie, Damián Blasi, Hedvig Skirgård, Simon J. Greenhill, Quentin
D. Atkinson and Russell D. Gray</p>
<p align="left">
 Of approximately 7,000 languages around the world, only a handful have
    abundant computational resources. Extending the reach of language technologies
    to diverse, less-resourced languages is important for tackling the challenges
    of digital equity and inclusion. Here we introduce the Grambank typological database
    as a resource to support such efforts. To date, work that uses typological data
    to extend computational research to less-resourced languages has relied on cross-linguistic
    morphosyntax datasets that are sparsely populated, use categorical coding that
    can be difficult to interpret, and introduce redundant information across features.
    Grambank presents similar information (e.g. word order, grammatical relation marking,
    constructions like interrogatives and negation), but is designed to avoid several
    disadvantages of legacy typological resources. Grambank’s 195 features encode
    basic information about morphology and syntax for 2,467 languages. 83% of these
    languages are annotated for at least 100 features. By implementing binary coding
    for most features and curating the dataset to avoid logical dependencies, Grambank
    presents information in a user-friendly format for computational applications.
    The scale, completeness, reliability, format, and documentation of Grambank make
    it a useful resource for linguistically-informed models, cross-lingual NLP, and
    research targeting less-resourced languages.</p>
   <iframe width="560" height="315" src="https://www.youtube.com/embed/3twsQoB1_90" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/grambanks-typological-advances.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/15_grambank_s_typological_advance.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p15" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>
       </div>
      </div>
    </div>


  <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse21">16:55 &ndash; 17:05 Language-Agnostic Measures Discriminate Inflection and Derivation</a>
        </h4>
      </div>
      <div id="collapse21" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Coleman Haley, Edoardo M. Ponti and Sharon Goldwater</p>
<p align="left">
In morphology, a distinction is commonly drawn between inflection and
    derivation. However, a precise definition of this distinction which captures the
    way the terms are used across languages remains elusive within linguistic theory,
    typically being based on subjective tests. In this study, we present 4 quantitative
    measures which use the statistics of a raw text corpus in a language to estimate
    how much and how variably a morphological construction changes aspects of the
    lexical entry, specifically, the word's form and the word's semantic and syntactic
    properties (as operationalised by distributional word embeddings). Based on a
    sample of 26 languages, we find that we can reconstruct 90\% of the classification
    of constructions into inflection and derivation in Unimorph using our 4 measures,
    providing large-scale cross-linguistic evidence that the concepts of inflection
    and derivation are associated with measurable signatures in terms of form and
    distribution signatures that behave consistently across a variety of languages.
    Critically, our measures and models are entirely language-agnostic, yet perform
    well across all languages studied. We find that while there is a high degree of
    consistency in the use of the terms inflection and derivation in terms of our
    measures, there are still many constructions near the model's decision boundary
    between the two categories, indicating a gradient, rather than categorical, distinction.</p>
 <!--iframe width="560" height="315" src="https://www.youtube.com/embed/TBA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe-->
<p align="center"><a href="workshops/2023/sigtyp/slides/TBA" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/14_language_agnostic_measures_dis.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p14" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>


   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse22">17:05 &ndash; 17:20 Does Topological Ordering of Morphological Segments Reduce Morphological
Modeling Complexity? A Preliminary Study on 13 Languages</a>
        </h4>
      </div>
      <div id="collapse22" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Andreas Shcherbakov and Kat Vylomova</p>
<p align="left">Generalization to novel forms and feature combinations is the key to efficient
    learning. Recently, Goldman et al. (2022) demonstrated that contemporary neural
    approaches to morphological inflection still struggle to generalize to unseen
    words and feature combinations, even in agglutinative languages. In this paper,
    we argue that the use of morphological segmentation in inflection modeling allows
    decomposing the problem into sub-problems of substantially smaller search space.
    We suggest that morphological segments may be globally topologically sorted according
    to their grammatical categories within a given language. Our experiments demonstrate
    that such segmentation provides all the necessary information for better generalization,
    especially in agglutinative languages.</p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/zN1uBtZVUp0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/morphological-ordering.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/21_Superpositional_Morphology__Step_by_Step_One_Goes_Fast.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p21" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>


   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse221">17:20 &ndash; 17:35 Multilingual End-to-end Dependency Parsing with Linguistic Typology knowledge</a>
        </h4>
      </div>
      <div id="collapse221" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Chinmay Choudhary and Colm O’riordan</p>
<p align="left">Prior research has investigated the impact of various linguistic features
    on cross-lingual transfer performance. In this study, we investigate the manner
    in which this effect can be mapped onto the representation space. While past studies
    have focused on the impact on cross-lingual alignment in multilingual language
    models during fine-tuning, this study examines the absolute evolution of the respective
    language representation spaces produced by MLLMs. We place a specific emphasis
    on the role of linguistic characteristics and investigate their inter-correlation
    with the impact on representation spaces and cross-lingual transfer performance.
    Additionally, this paper provides preliminary evidence of how these findings can
    be leveraged to enhance transfer to linguistically distant languages.</p>
  <!--iframe width="560" height="315" src="https://www.youtube.com/embed/TBA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe-->
<p align="center"><a href="workshops/2023/sigtyp/slides/multilig-end-to-end-dp.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/2_multilingual_end_to_end_depend.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p2" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>    


   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse222">17:35 &ndash; 17:50 Using Modern Languages to Parse Ancient Ones: a Test on Old English</a>
        </h4>
      </div>
      <div id="collapse222" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Luca Brigada Villa and Martina Giarda</p>
<p align="left">In this paper we test the parsing performances of a multilingual parser
    on Old English data using different sets of languages, alone and combined with
    the target language, to train the models. We compare the results obtained by the
    models and we analyze more in deep the annotation of some peculiar syntactic constructions
    of the target language, providing plausible linguistic explanations of the errors
    made even by the best performing models.</p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/Bp18utIZE20" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/a-test-on-old-english.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/4_using_modern_languages_to_pars.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p4" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>    


 <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse223">17:50 &ndash; 18:05 Corpus-based Syntactic Typological Methods for Dependency Parsing Improvement</a>
        </h4>
      </div>
      <div id="collapse223" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By Diego Alves, Božo Bekavac, Daniel Zeman and Marko Tadić</p>
<p align="left">This article presents a comparative analysis of four different syntactic
    typological approaches applied to 20 different languages to determine the most
    effective one to be used for the improvement of dependency parsing results via
    corpora combination. We evaluated these strategies by calculating the correlation
    between the language distances and the empirical LAS results obtained when languages
    were combined in pairs. From the results, it was possible to observe that the
    best method is based on the extraction of word order patterns which happen inside
    subtrees of the syntactic structure of the sentences.</p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/4jvEPYMXSu4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p align="center"><a href="workshops/2023/sigtyp/slides/dependency-parsing-improvement.pdf" class="button small" >Slides</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2023/sigtyp/papers/10_corpus_based_syntactic_typolog.pdf" class="button small">Paper</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/sigtyp23-p10" class="button small">Discuss&nbsp;<font color="#FF9999">&#10095;&#10095;</font></a></p>

       </div>
      </div>
    </div>    


<br/>
  <div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse30" style="font-size:18px">18:05 &ndash; 18:10 Closing Session</a>
        </h4>
      </div>
      <div id="collapse30" class="panel-collapse collapse">
        <div class="panel-body" style="align: center; text-align:center">
<p align="left" style="color:blue"> By SIGTYP2023 Organizing Committee</p>
<p align="left">
Stay with us for SIGTYP 2024!
<br/>
THANK YOU ALL!
</p>

</div>
      </div>
    </div>
    
</div>
<br/>
<br/>


<!--p style="font-size:18px">You may also <a href="http://">Read it in PDF</a></p-->

						</section>
					</div>
					
				</div>
			</div>
		</div>
	
	<!-- Copyright -->
		<div id="copyright">
			<div class="container">
				Contact Email: <a href="mailto:sigtyp AT gmail DOT com"> sigtyp AT gmail DOT com </a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  WebMaster: <a href="http://kat.academy">EKATERINA VYLOMOVA</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Design: <a href="http://templated.co">TEMPLATED</a>
			</div>
		</div>


	</body>
</html>
