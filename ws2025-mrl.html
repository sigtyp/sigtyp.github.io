<!DOCTYPE HTML>
<!--
	Imagination by TEMPLATED
    templated.co @templatedco
    Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>

<head>
	<title>4TH MULTILINGUAL REPRESENTATION LEARNING (MRL) WORKSHOP @EMNLP 2025</title>
	<link rel="shortcut icon" type="image/x-icon" href="images/favicon.ico" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="description" content="SIGTYP" />
	<meta name="keywords" content="SIGTYP" , "MRL2025"  />
	<link href='http://fonts.googleapis.com/css?family=Raleway:400,100,200,300,500,600,700,800,900' rel='stylesheet'
		type='text/css'>
	<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
	<script src="js/skel.min.js"></script>
	<script src="js/skel-panels.min.js"></script>
	<script src="js/init.js"></script>
	<noscript>
		<link rel="stylesheet" href="css/skel-noscript.css" />
		<link rel="stylesheet" href="css/style.css" />
		<link rel="stylesheet" href="css/style-desktop.css" />
	</noscript>
</head>

<body>

	<div id="header-wrapper">

		<!-- Header -->
		<div id="header">
			<div class="container">

				<!-- Logo -->
				<div id="logo">
					<a href="index.html"><img src="images/sigtyp1.jpg" style="width:70px" alt="SIGTYP"></a>
					<!--h1><a href="#"><font color=red>S</font>IG<font color=red>T</font>YP</a></h1-->
				</div>

				<!-- Nav -->
				<nav id="nav">
					<ul>
						<li><a href="index.html">Homepage</a></li>
						<li><a href="constitution.html">Constitution</a></li>
						<li><a href="members.html">Members</a></li>
						<li class="active"><a href="workshop.html">Workshop</a></li>
						<li><a href="lectures.html">Lectures</a></li>
						<li><a href="blog.html">Blog</a></li>
					</ul>
				</nav>

			</div>
		</div>
		<!-- Header -->

		<!-- Banner -->
		<div id="banner">
			<div class="container">

				<section>
					<!--span class="fa fa-cubes"></span-->
					<header>
						<h2> </h2>
						<h2> </h2>
						<h2> </h2>
						<span class="byline"> </span>
					</header>
					<!--a href="#" class="button medium">Fusce ultrices fringilla</a-->
				</section>
			</div>
		</div>
		<!-- /Banner -->

	</div>

	<!-- Main -->
	<div id="main">
		<div class="container">
			<div class="row">

				<div class="9u skel-cell-important">
					<section>
						<header>
							<h2 style="font-size:26px" align="center"> 5TH MULTILINGUAL REPRESENTATION LEARNING (MRL)
								WORKSHOP 2025</h2>
						</header>
						<p style="font-size:16px" align="center">
							<strong>CO-LOCATED WITH EMNLP IN SUZHOU, CHINA NOVEMBER 5th - 9th 2025</strong><br />

							<br />
							<hr style="border-top: dotted 2px;" /> <br />

							<header>

								<h2 style="font-size:27px">Keynote Speakers</h2>
							</header>

							<div class="row">
								 <div class="column">
									<a href="http://www0.cs.ucl.ac.uk/people/P.Stenetorp.html"><img
											src="workshops/2025/mrl/speakers/P.Stenetorp.jpg" alt="Pontus Stenetorp"
											style="height:110px"><br />
										<a href="http://www0.cs.ucl.ac.uk/people/P.Stenetorp.html">Pontus Stenetorp, UCL</a><br />
								
								</div>
								<div class="column">
									<a href="https://aliceoh9.github.io/"><img
											src="workshops/2025/mrl/speakers/alice_oh.jpg" alt="Alice Oh"
											style="height:110px"><br />
										<a href="https://aliceoh9.github.io/">Alice Oh, KAIST</a><br />
								</div>
								 <div class="column">
									<a href="https://kellymarchisio.github.io/"><img
											src="workshops/2025/mrl/speakers/kelly_marchisio.png" alt="=Kelly Marchisio.png"
											style="height:110px"><br />
										<a href="https://kellymarchisio.github.io/">Kelly Marchisio, Cohere</a><br />
								
								</div>
								

							</div>
							<br />
					
					
							<!-- <hr style="border-top: dotted 2px;" /> <br /> -->

							<!-- Here goes the schedule 
							
							<header>
								<h2 style="font-size:27px">Workshop Schedule</h2>
								
							</header> -->

						<!-- <h2 class="c1">Workshop Location: L1 in Leo 3&4</h2>
						<h2 class="c1">Poster Session Location: East Foyer located on B2</h2> -->
								
							<br />
							<!-- <table class="tableizer-table">
							<tbody>
							<tr><td>09:00 - 09:10</td><td>&nbsp; Opening remarks</td></tr>
							<tr><td>09:10 - 09:50</td><td>&nbsp; Invited talk by </td></tr>
							 <tr><td>09:50 - 10:30</td><td>&nbsp; Invited talk by </td></tr>
							 <tr><td>10:30 - 11:00</td><td>&nbsp; Coffee Break</td></tr>
							 <tr><td>11:00 - 12:30</td><td>&nbsp; Poster Session</td></tr>
							 <tr><td>12:30 - 14:00</td><td>&nbsp; Lunch Break</td></tr>
							 <tr><td>14:00 - 14:30</td><td>&nbsp; Shared Task Session 
								<ul>
									<li class="c4">&#8226;&nbsp;Findings Paper</li>
									<li class="c4">&#8226;&nbsp;Winning team presentation</li>
								</ul>
							 </td></tr>
							 <tr><td>14:30 - 15:30</td><td>&nbsp; Best Paper Session
								<ul>
									<li class="c4">&#8226;&nbsp;Best Paper</li>
									<li class="c4">&#8226;&nbsp;Honorable Mentions</li>
								</ul>
							 </td></tr>
							 <tr><td>15:30 - 16:00</td><td>&nbsp; Coffee Break</td></tr>
							 <tr><td>16:00 - 16:50</td><td>&nbsp; Invited talk by Orhan Firat</td></tr>
							 <tr><td>16:50 - 17:00</td><td>&nbsp; Closing remarks</td></tr>
							</tbody></table>		 -->
							
							
                                    <!-- <h2 class="c1">Best Paper Award</h2>
                                    <span class="c4">&#8226; Embedding Structure Matters: Comparing Methods to Adapt Multilingual Vocabularies to New Languages<br></span>
                                        <span class="c4 c15">C.M. Downey, Terra Blevins, Nora Goldfine and Shane Steinert-Threlkeld</span>
                                        <h2 class="c3">Honorable Mentions</h2>
                                            <span class="c4">&#8226; Meta-learning For Vision-and-language Cross-lingual Transfer<br></span>
                                            <span class="c9">Hanxu Hu and Frank Keller</span>
                                            <br>
                                            <span class="c4">&#8226; Adapt and Prune Strategy for Multilingual Speech Foundational Model on Low-resourced Languages</span><br>
                                            <span class="c9">Hyeon Soo Kim, Chung Hyeon Cho, Hyejin Won and Kyung Ho Park</span> -->
										
								</p>
							<hr style="border-top: dotted 2px;" /> <br />
							<header>
								<h2 style="font-size:27px">Workshop Schedule</h2>
							</header>
							
							<table class="tableizer-table">
								<tbody>
								<tr><td>09:00 - 09:10</td><td>&nbsp; Opening remarks</td></tr>
								<tr><td>09:10 - 09:50</td><td>&nbsp; Invited talk by TBD </td></tr>
								 <tr><td>09:50 - 10:30</td><td>&nbsp; Invited talk by TBD </td></tr>
								 <tr><td>10:30 - 11:00</td><td>&nbsp; Coffee Break</td></tr>
								 <tr><td>11:00 - 12:30</td><td>&nbsp; Poster Session</td></tr>
								 <tr><td>12:30 - 14:00</td><td>&nbsp; Lunch Break</td></tr>
								 <tr><td>14:00 - 14:30</td><td>&nbsp; Shared Task Session 
									<ul>
										<li class="c4">&#8226;&nbsp;Findings Paper</li>
										<li class="c4">&#8226;&nbsp;Winning team presentation</li>
									</ul>
								 </td></tr>
								 <tr><td>14:30 - 15:30</td><td>&nbsp; Best Paper Session
									<ul>
										<li class="c4">&#8226;&nbsp;Best Paper</li>
										<li class="c4">&#8226;&nbsp;Honorable Mentions</li>
									</ul>
								 </td></tr>
								 <tr><td>15:30 - 16:00</td><td>&nbsp; Coffee Break</td></tr>
								 <tr><td>16:00 - 16:50</td><td>&nbsp; Invited talk by TBD </td></tr>
								 <tr><td>16:50 - 17:00</td><td>&nbsp; Closing remarks</td></tr>
								</tbody></table>

							<header>
								<h2 style="font-size:27px">Workshop Description</h2>
							</header>

							<p style="font-size:17px">Multi-lingual representation learning methods have recently been
								found to be extremely efficient in learning features useful for transfer learning
								between languages and demonstrating potential in achieving successful adaptation of
								natural language processing (NLP) models into languages or tasks with little to no
								training resources. On the other hand, there are many aspects of such models which have
								the potential for further development and analysis in order to prove their applicability
								in various contexts. These contexts include different NLP tasks and also understudied
								language families, which face important obstacles in achieving practical advances that
								could improve the state-of-the-art in NLP of various low-resource or underrepresented
								languages.
								</br></br>
								This workshop aims to bring together the research community consisting of scientists
								studying different aspects in multilingual representation learning, currently the most
								promising approach to improve the NLP in low-resource or underrepresented languages, and
								provide the rapidly growing number of researchers working on the topic with a means of
								communication and an opportunity to present their work and exchange ideas. The main
								objectives of the workshop will be:
								</br></br>
							</p>

							<ul>
								<li>&nbsp;&nbsp;&nbsp;&#8226; To construct and present a wide array of multi-lingual
									representation learning methods, including their theoretical formulation and
									analysis, practical aspects such as the application of current state-of-the-art
									approaches in transfer learning to different tasks or studies on adaptation into
									previously under-studied context;</li>
								<li>&nbsp;&nbsp;&nbsp;&#8226; To provide a better understanding on how the language
									typology may impact the applicability of these methods and motivate the development
									of novel methods that are more generic or competitive in different languages;</li>
								<li>&nbsp;&nbsp;&nbsp;&#8226; To promote collaborations in developing novel software
									libraries or benchmarks in implementing or evaluating multi-lingual models that
									would accelerate progress in the field.</li>
							</ul>
							</br></br>

							<p style="font-size:17px">
								By allowing a communication means for research groups working on machine learning,
								linguistic typology, or real-life applications of NLP tasks in various languages to
								share and discuss their recent findings, our ultimate goal is to support rapid
								development of NLP methods and tools that are applicable to a wider range of languages.
							</p>

							<br />
							
							<hr style="border-top: dotted 2px;" /> <br />
						
							<header>
								<h2 style="font-size:27px">Accepted Papers</h2>
							</header>

							
							<hr style="border-top: dotted 2px;" /> <br />
						
							 <header>
								<h2 style="font-size:27px">Main Topics</h2>
							</header>
							<p style="font-size:17px">Topics of interest include, but are not limited to:</p>

							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Understanding the learning dynamics of
								multi-lingual representation learning methods</p>
							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Multilingual pretraining for
								discriminative and generative downstream tasks </p>
							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Probing and analysis of multilingual
								representations </p>
							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; New methods for multi-lingual
								representation learning </p>
							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; New approaches to language adaptation
								of NLP systems </p>

							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Zero-shot and few-shot learning for
								multilingual NLP</p>

							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Investigating and understanding
								transfer learning methods for adaptation of NLP systems into previously under-studied
								languages, such as morphologically-rich languages</p>
							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Data sets, benchmarks or libraries for
								implementing and evaluating multi-lingual models </p>




							<br />
							<hr style="border-top: dotted 2px;" /> <br />
							<header>
								<h2 style="font-size:27px">Submissions</h2>
							</header>
							<p style="font-size:17px">
								<strong>Research papers:</strong> We invite all potential participants to submit their
								novel research contributions in the related fields as long papers following the EMNLP
								2023 long paper format (anonymized with 8 pages excluding the references, and an
								additional page for the camera-ready versions for the accepted papers). All accepted
								research papers will be published as part of our workshop proceedings and presented
								either as oral or poster presentations.
								Our research paper track will accept submissions through our own submission system
								available at <a href="https://openreview.net/group?id=EMNLP/2024/Workshop/MRL">MRL 2024 OpenReview
									Submission</a>.</strong>
							</p>
							<br />
							<p style="font-size:17px">
								<strong>Extended abstracts:</strong> Besides long paper submissions, we also invite
								previously published or ongoing and incomplete research contributions to our
								non-archival extended abstract track. All extended abstracts can use the same EMNLP
								template with a 2-page limit, excluding the bibliography. </strong>
							</p>
							<br />
										
							<br>
							

						
<!-- 
						<hr style="border-top: dotted 2px;" /> <br /> 

<header>
	<h2 style="font-size:27px">Findings Papers</h2>
</header>

<!-- <ul>
<li class="c4"><span>&#8226;&nbsp;mLongT5: A Multilingual and Efficient Text-To-Text Transformer forLonger Sequences</span><span class="c0">&nbsp;<br></span><span class="c2">David Uthus,Santiago Ontanon,Joshua Ainslie,Mandy Guo</span></li><br>
<li class="c4"><span>&#8226;&nbsp;ICU: Conquering Language Barriers in Vision-and-Language Modeling by Dividing the Tasks into Image Captioning and Language Understanding</span><span class="c0">&nbsp;<br></span><span class="c2">Guojun Wu</span></li><br>
<li class="c4"><span>&#8226;&nbsp;TRIP: Accelerating Document-level Multilingual Pre-training via Triangular Document-level Pre-training on Parallel Data Triplets</span><span class="c0">&nbsp;<br></span><span class="c2">Hongyuan Lu,Haoyang Huang,Shuming Ma,Dongdong Zhang,Wai Lam,Zhaochuan Gao,Anthony Aue,Arul Menezes,Furu Wei</span></li><br>
<li class="c4"><span>&#8226;&nbsp;mmT5: Modular Multilingual Pre-Training Solves Source Language Hallucinations</span><span class="c0">&nbsp;<br></span><span class="c2">Jonas Pfeiffer,Francesco Piccinno,Massimo Nicosia,Xinyi Wang,Machel Reid,Sebastian Ruder</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Diversifying language models for lesser-studied languages and language-usage contexts: A case of second language Korean</span><span class="c0">&nbsp;<br></span><span class="c2">Hakyung Sung,Gyu-Ho Shin</span></li><br>
<li class="c4"><span>&#8226;&nbsp;TaTA: A Multilingual Table-to-Text Dataset for African Languages</span><span class="c0">&nbsp;<br></span><span class="c2">Sebastian Gehrmann,Sebastian Ruder,Vitaly Nikolaev,Jan A. Botha,Michael Chavinda,Ankur P Parikh,Clara E. Rivera</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Romanization-based Large-scale Adaptation of Multilingual Language Models</span><span class="c0">&nbsp;<br></span><span class="c2">Sukannya Purkayastha,Sebastian Ruder,Jonas Pfeiffer,Iryna Gurevych,Ivan Vulić</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Exploring the Effectiveness of Multi-Lingual Commonsense Knowledge-Aware Open-Domain Dialogue Response Generation</span><span class="c0">&nbsp;<br></span><span class="c2">Sixing Wu,Jiong Yu,Tianshi Che,Yang Zhou,Wei Zhou</span></li><br>
<li class="c4"><span>&#8226;&nbsp;PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning</span><span class="c0">&nbsp;<br></span><span class="c2">Yongil Kim,Yerin Hwang,Hyeongu Yun,Seunghyun Yoon,Trung Bui,Kyomin Jung</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs</span><span class="c0">&nbsp;<br></span><span class="c2">Yihong Liu,Haotian Ye,Leonie Weissweiler,Renhao Pei,Hinrich Schuetze</span></li><br>
<li class="c4"><span>&#8226;&nbsp;A Joint Matrix Factorization Analysis of Multilingual Representations</span><span class="c0">&nbsp;<br></span><span class="c2">Zheng Zhao,Yftah Ziser,Bonnie L. Webber,Shay B Cohen</span></li><br>
<li class="c4"><span>&#8226;&nbsp;MEEP: Is this Engaging? Prompting Large Language Models for Dialogue Evaluation in Multilingual Settings</span><span class="c0">&nbsp;<br></span><span class="c2">Amila Ferron,Amber Shore,Ekata Mitra,Ameeta Agrawal</span></li><br>
<li class="c4"><span>&#8226;&nbsp;X-SNS: Cross-Lingual Transfer Prediction through Sub-Network Similarity</span><span class="c0">&nbsp;<br></span><span class="c2">Taejun Yun,Jinhyeon Kim,Deokyeong Kang,Seonghoon Lim,Jihoon Kim,Taeuk Kim</span></li><br>
<li class="c4"><span>&#8226;&nbsp;KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model</span><span class="c0">&nbsp;<br></span><span class="c2">Lei Geng,Xu Yan,Ziqiang Cao,Juntao Li,Wenjie Li,Sujian Li,Xinjie Zhou,Yang Yang,Jun Zhang</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Good Meta-tasks Make A Better Cross-lingual Meta-transfer Learning for Low-resource Languages</span><span class="c0">&nbsp;<br></span><span class="c2">Linjuan Wu,Zongyi Guo,Baoliang Cui,Haihong Tang,Weiming Lu</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Multilingual Generation and Answering of Questions from Texts and Knowledge Graphs</span><span class="c0">&nbsp;<br></span><span class="c2">Kelvin Han,Claire Gardent</span></li><br>
<li class="c4"><span>&#8226;&nbsp;A Multi-Modal Multilingual Benchmark for Document Image Classification</span><span class="c0">&nbsp;<br></span><span class="c2">Yoshinari Fujinuma,Siddharth Varia,Nishant Sankaran,Srikar Appalaraju,Bonan Min,Yogarshi Vyas</span></li><br>
<li class="c4"><span>&#8226;&nbsp;CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation</span><span class="c0">&nbsp;<br></span><span class="c2">Weixiang Yan,Yuchen Tian,Yunzhe Li,Qian Chen,Wen Wang</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Extrapolating Multilingual Understanding Models as Multilingual Generators</span><span class="c0">&nbsp;<br></span><span class="c2">Bohong Wu,Fei Yuan,hai zhao,Lei Li,Jingjing Xu</span></li><br>
<li class="c4"><span>&#8226;&nbsp;GlotLID: Language Identification for Low-Resource Languages</span><span class="c0">&nbsp;<br></span><span class="c2">Amir Hossein Kargaran,Ayyoob Imani,François Yvon,Hinrich Schuetze</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Take a Closer Look at Multilinguality! Improve Multilingual Pre-Training Using Monolingual Corpora Only</span><span class="c0">&nbsp;<br></span><span class="c2">Jinliang Lu,Yu Lu,Jiajun Zhang</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Is Robustness Transferable across Languages in Multilingual Neural Machine Translation?</span><span class="c0">&nbsp;<br></span><span class="c2">Leiyu Pan,Deyi Xiong</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Dialect-to-Standard Normalization: A Large-Scale Multilingual Evaluation</span><span class="c0">&nbsp;<br></span><span class="c2">Olli Kuparinen,Aleksandra Miletić,Yves Scherrer</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting</span><span class="c0">&nbsp;<br></span><span class="c2">Haoyang Huang,Tianyi Tang,Dongdong Zhang,Xin Zhao,Ting Song,Yan Xia,Furu Wei</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Towards a Deep Understanding of Multilingual End-to-End Speech Translation</span><span class="c0">&nbsp;<br></span><span class="c2">Haoran Sun,Xiaohu Zhao,Yikun Lei,shaolin Zhu,Deyi Xiong</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Towards Multilingual Interlinear Morphological Glossing</span><span class="c0">&nbsp;<br></span><span class="c2">Shu Okabe,François Yvon</span></li><br>
<li class="c4"><span>&#8226;&nbsp;T-Projection: High Quality Annotation Projection for Sequence Labeling Tasks</span><span class="c0">&nbsp;<br></span><span class="c2">Iker García-Ferrero,Rodrigo Agerri,German Rigau</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Breaking the Language Barrier: Improving Cross-Lingual Reasoning with Structured Self-Attention</span><span class="c0">&nbsp;<br></span><span class="c2">Negar Foroutan,Mohammadreza Banaei,Karl Aberer,Antoine Bosselut</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot Performance via Probability Calibration</span><span class="c0">&nbsp;<br></span><span class="c2">Ercong Nie,Helmut Schmid,Hinrich Schuetze</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Interpreting Indirect Answers to Yes-No Questions in Multiple Languages</span><span class="c0">&nbsp;<br></span><span class="c2">Zijie Wang,Md Mosharaf Hossain,Shivam Mathur,Terry Cruz Melo,Kadir Bulut Ozler,Keun Hee Park,Jacob Quintero,MohammadHossein Rezaei,Shreya Nupur Shakya,Md Nayem Uddin,Eduardo Blanco</span></li><br>
<li class="c4"><span>&#8226;&nbsp;BERTwich: Extending BERT’s Capabilities to Model Dialectal and Noisy Text</span><span class="c0">&nbsp;<br></span><span class="c2">Aarohi Srivastava,David Chiang</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Isotropic Representation Can Improve Zero-Shot Cross-Lingual Transfer on Multilingual Language Models</span><span class="c0">&nbsp;<br></span><span class="c2">Yixin Ji,Jikai Wang,Juntao Li,Hai Ye,Min Zhang</span></li><br>
<li class="c4"><span>&#8226;&nbsp;One For All & All For One: Bypassing Hyperparameter Tuning with Model Averaging for Cross-Lingual Transfer</span><span class="c0">&nbsp;<br></span><span class="c2">Fabian David Schmidt,Ivan Vulić,Goran Glavaš</span></li><br>
<li class="c4"><span>&#8226;&nbsp;Multilingual Lottery Tickets to Pretrain Language Models</span><span class="c0">&nbsp;<br></span><span class="c2">Jaeseong Lee,seung-won hwang</span></li><br>
<li class="c4"><span>&#8226;&nbsp;In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages</span><span class="c0">&nbsp;<br></span><span class="c2">Asım Ersoy,Gerson Vizcarra,Tahsin Mayeesha,Benjamin Muller</span></li><br>

</ul> -->
							<hr style="border-top: dotted 2px;" /> <br /> 
							<header>
								<h2 style="font-size:27px">Shared Task</h2>
							</header>
							<p style="font-size:17px">
								MRL 2024 continues <a href="st2024-mrl.html">the 2nd shared task on Multi-task Multi-lingual Information Retrieval</a>, which provides a new multilingual evaluation benchmark for assessment of large scale representation learning models in a diverse set of under-represented languages in a range of predictive and generative tasks. 
							</p>
							
						
							<br />
							<hr style="border-top: dotted 2px;" /> <br />

							<header>
								<h2 style="font-size:27px">Important Dates</h2>
							</header>

							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Sep. 1, 2024: Paper Due Date
							</p>
							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Oct. 3, 2024: Notification of
									Acceptance  </p>
							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Oct. 10, 2024: Camera-ready papers due
							</p>
							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Nov. 15-16, 2024: Workshop </p>
							<p style="font-size:17px"> &nbsp;&nbsp;&nbsp;&#8226; Nov. 12-14, 2024: Main conference </p>

							<p style="font-size:17px">
								(All deadlines are 11.59 pm UTC -12h (“anywhere on Earth”))
							</p>

							<br />
							<hr style="border-top: dotted 2px;" /> <br />

							<header>
								<h2 style="font-size:27px">Organizers</h2>
							</header>
							<p style="font-size:17px">
								<table style="border-collapse: separate; border-spacing: 20px 0;">
									<thead>
										<tr>
											<th><a href="https://dadelani.github.io">David Ifeoluwa Adelani, McGill University and Mila</a></th>
											<th><a href="https://www.duyguataman.com">Duygu Ataman, New York University</a></th>
											<td><a href="https://www.linkedin.com/in/mammadhajili">Mammad Hajili,
													Microsoft</a></td>
											<th><a href="https://owos.github.io">Abraham Owodunni, OSU and Masakhane</a></th>
											<th><a href="https://www.jonnesaleva.com">Jonne Sälevä, Brandeis University</a></th>
											<th><a href="https://davidstap.github.io">David Stap, University of Amsterdam</a></th>
											<th><a href="https://www.researchgate.net/profile/Francesco-Tinner">Francesco
													Tinner, University of Amsterdam</a></th>



										</tr>
									</thead>

								</table>
							</p>
							<br />
							<hr style="border-top: dotted 2px;" /> <br />

							<header>
								<h2 style="font-size:27px; padding: 20px">Sponsors</h2>
							</header>
							<p style="font-size:17px"> Interested in being a Sponsor? <a
									href="mailto:mrlworkshop2024@gmail.com">Contact us!</a> </p>


					</section>
				</div>

				<div class="3u">
					<section class="sidebar">
						<header>
							<h2>Workshops</h2>
						</header>
						<ul class="default">
							<li><a href="ws2025-mrl.html">&raquo; <font color="red"> MRL 2025 </font></a></li>
							<li><a href="ws2025-sigtyp.html">&raquo; SIGTYP 2025</a></li>
                           			       <li><a href="ws2024-mrl.html">&raquo; MRL 2024</a></li>
							<li><a href="ws2024-sigtyp.html">&raquo; SIGTYP 2024</a></li>
							<li><a href="ws2023-sigtyp.html">&raquo; SIGTYP 2023</a></li>
							<li><a href="ws2023-mrl.html">&raquo; MRL 2023</a></li>
							<li><a href="ws2022-sigtyp.html">&raquo; SIGTYP 2022</a></li>
							<li><a href="ws2022-mrl.html">&raquo; MRL 2022</a></li>
							<li><a href="ws2021.html">&raquo; SIGTYP 2021</a></li>
							<li><a href="ws2020.html">&raquo; SIGTYP 2020</a></li>
							<li><a href="ws2019.html">&raquo; TyP-NLP 2019</a></li>
						</ul>
						<br /><br />
						<header>
							<h2>Shared Tasks</h2>
						</header>
						<ul class="default">
							<li><a href="st2024-mrl.html">&raquo; MRL 2024 Shared Task on Multi-lingual Multi-task
								Information Retrieval</a></li>
							<li><a href="st2024.html">&raquo; 2024: Word Embedding Evaluation for Ancient and Historical Languages</a></li>
							<li><a href="st2023-mrl.html">&raquo; MRL 2023 Shared Task on Multi-lingual Multi-task
									Information Retrieval</a></li>
							<li><a href="st2023.html">&raquo; 2023: Cognate and Derivative Detection for Low-Resourced
									Languages</a></li>
							<li><a href="st2022.html">&raquo; 2022: Prediction of Cognate Reflexes</a></li>
							<li><a href="st2022-mrl.html">&raquo; 2022 (MRL): Multilingual Clause-level Morphology</a>
							</li>
							<li><a href="st2021.html">&raquo; 2021: Robust Language ID from Speech</a></li>
							<li><a href="st2020.html">&raquo; 2020: Prediction of Typological Features</a></li>
						</ul>
					</section>

				</div>

			</div>
		</div>
	</div>
	<!-- Main -->


	<!-- Copyright -->
	<div id="copyright">
		<div class="container">
			Contact Email: <a href="mailto:mrlworkshop2024@gmail.com"> mrlworkshop2024@gmail.com </a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			WebMaster: <a href="http://kat.academy">EKATERINA VYLOMOVA</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Design: <a
				href="http://templated.co">TEMPLATED</a>
		</div>
	</div>


</body>

</html>
