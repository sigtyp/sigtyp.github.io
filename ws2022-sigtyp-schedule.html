<!DOCTYPE HTML>
<!--
	Imagination by TEMPLATED
    templated.co @templatedco
    Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>SIGTYP -- Workshop 2022 Schedule</title>
		<link rel="shortcut icon" type="image/x-icon" href="images/favicon.ico" />
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="sigtyp,sigtyp2020,emnlp,workshop,typology,linguistics,multilinguality" />
		<link href='http://fonts.googleapis.com/css?family=Raleway:400,100,200,300,500,600,700,800,900' rel='stylesheet' type='text/css'>
		<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  		<!--script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script-->
  		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
		<script src="js/skel.min.js"></script>
				<script src="js/skel-panels.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel-noscript.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-desktop.css" />
		</noscript>

		


	</head>
	<body>

	<div id="header-wrapper">

		<!-- Header -->
			<div id="header">
				<div class="container">
						
					<!-- Logo -->
						<div id="logo">
							<a href="index.html"><img src="images/sigtyp1.jpg"  style="width:70px" alt="SIGTYP"></a>
							<!--h1><a href="#"><font color=red>S</font>IG<font color=red>T</font>YP</a></h1-->
						</div>
					
					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Homepage</a></li>
								<li><a href="constitution.html">Constitution</a></li>
								<li><a href="members.html">Members</a></li>
								<li class="active"><a href="workshop.html">Workshop</a></li>
								<li><a href="lectures.html">Lectures</a></li>
								<li><a href="blog.html">Blog</a></li>
							</ul>
						</nav>
	
				</div>
			</div>
		<!-- Header -->

		<!-- Banner -->
			<div id="banner">
				<div class="container">
	
					<section>
						<!--span class="fa fa-cubes"></span-->
						<header>
							<h2 > </h2>
							<h2 > </h2>
<h2 > </h2>
							<span class="byline"> </span>
						</header>
						<!--a href="#" class="button medium">Fusce ultrices fringilla</a-->
					</section>	
				</div>
			</div>
		<!-- /Banner -->

	</div>

	<!-- Main -->
		<div id="main">
			<div class="container">
				<div class="row">
		
									
					<div class="container">
						<section>
							<header>
							
							<h2>  <font color="red">S</font><font color="yellow">I</font><font color="green">G</font><font color="brown">T</font><font color="blue">Y</font><font color="purple">P</font>2022 — JULY,14th — 508-Tahuya/Hybrid</h2> </header>
<hr/>							
<p style="font-size:18px">

<strong>Time zone: America/Seattle</strong>
							</p>
<!--div class="container"-->
  <!--h3 style="font-size:21px"><font color="red">&#10043;</font>&nbsp;THESES&nbsp;<font color="red">&#10043;</font>&nbsp;</h3><br/-->
  <div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse1" style="font-size:18px">8:30 &ndash; 8:40  Opening Session</a>
        </h4>
      </div>
      <div id="collapse1" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By SIGTYP2022 Organizing Committee</p>
<p>
Opening remarks: general comments about SIGTYP development, SIGTYP2022 submissions, shared task, etc. 
</p>

</div>
      </div>
    </div>
<br/> 
<h3 style="font-size:21px"><font color="green">&#10043;</font>&nbsp;Keynote Talk&nbsp;<font color="green">&#10043;</font></h3><br/>
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse2">8:40 &ndash; 9:30 Kristen Howell: Grammar Inference for Local Languages. Leveraging Typology for Automatic Grammar Generation</a>
        </h4>
      </div>
      <div id="collapse2" class="panel-collapse collapse">
        <div class="panel-body">
<p>
<img src="workshops/2022/sigtyp/speakers/kristen.jpeg" alt="Kristen Howell" style="height:110px;float:left;margin:9px"/>
Kristen Howell is a data scientist at LivePerson Inc. in Seattle, Washington. Her research interests range from grammar engineering and grammar inference to conversational NLP. Throughout this research, the common thread is multilingual NLP across typologically diverse languages. Kristen received her PhD from the University of Washington in 2020, where she engaged with typological literature to develop technology for automatically generating grammars for local languages. Recent work at LivePerson has focused on multilingual NLP, leveraging deep learning techniques for conversational AI.
<br/>
In this talk Kristen will describe the benefit of implemented grammars as well as the challenges involved in creating them. She presents an inference system that can be used to automatically generate such grammars on the basis of interlinear glossed text (IGT) corpra. The inference system, called BASIL -- Building Analyses from Syntactic Inference in Local Languages, leverages typologically informed heuristics to infer syntactic and morphological information from linguistic corpora to select analyses that model the language. She will engage with the question of whether and to what extent typological features are apparent in IGT data and how effectively grammars generated with these features can model human language.	
</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Slides</a>&nbsp;&nbsp;&nbsp;<a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="https://linguistics.washington.edu/people/kristen-howell" class="button small"> Kristen's Website</a></p>
	</div>
      </div>
    </div>
  <br/>
  <h3 style="font-size:21px"><font color="purple">&#10043;</font>&nbsp;Multilingual Representations (Long Talks)&nbsp;<font color="purple">&#10043;</font></h3><br/>

   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse3">09:30 &ndash; 09:45 Multilingualism Encourages Recursion: a Transfer Study with mBERT</a>
        </h4>
      </div>
      <div id="collapse3" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Andrea Gregor De Varda and Roberto Zamparelli</p>
<p>
The present work constitutes an attempt to investigate the relational structures learnt by mBERT, a multilingual transformer-based network, with respect
    to different cross-linguistic regularities proposed in the fields of theoretical and quantitative linguistics. We pursued this objective by relying on a zero-shot
    transfer experiment, evaluating the model's ability to generalize its native task to artificial languages that could either respect or violate some proposed language
    universal, and comparing its performance to the output of BERT, a monolingual model with an identical configuration. We created four artificial corpora through
    a Probabilistic Context-Free Grammar by manipulating the distribution of tokens and the structure of their dependency relations. We showed that while both models
    were favoured by a Zipfian distribution of the tokens and by the presence of head-dependency type structures, the multilingual transformer network exhibited a stronger reliance
    on hierarchical cues compared to its monolingual counterpart.</p>
   <iframe width="560" height="315" src="https://www.youtube.com/embed/z4dPrKxGRG0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small" >BiliBili</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP1.pdf" class="button small">Paper PDF</a></p>
       </div>
      </div>
    </div>



   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse4">09:45 &ndash; 10:00 Cross-linguistic Comparison of Linguistic Feature Encoding in BERT Models for
Typologically Different Languages</a>
        </h4>
      </div>
      <div id="collapse4" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Yulia Otmakhova, Karin Verspoor and Jey Han Lau</p>
<p>
 Though recently there have been an increased interest in how pre-trained language models encode different linguistic features, there is still a lack of systematic comparison between languages with different morphology and syntax. In this paper, using BERT as an example of a pre-trained model, we compare how three typologically different languages (English, Korean, and Russian) encode morphology and syntax features across different layers. In particular, we contrast languages which differ in a particular aspect, such as flexibility of word order, head directionality, morphological type, presence of grammatical gender, and morphological richness, across four different tasks.</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP6.pdf" class="button small">Paper PDF</a></p>

       </div>
      </div>
    </div>




    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse5">10:00 &ndash; 10:10 Coffee Break</a>
        </h4>
      </div>
      <div id="collapse5" class="panel-collapse collapse">
        <div class="panel-body">
<p>
Coffee break, chats, linguistic trivia
</p>
       </div>
      </div>
    </div>


  <br/>
  <h3 style="font-size:21px"><font color="blue">&#10043;</font>&nbsp;Typology (Short Talks)&nbsp;<font color="blue">&#10043;</font></h3><br/>

   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse6">10:10 &ndash; 10:22 Word-order Typology in Multilingual BERT: A Case Study in Subordinate-Clause
Detection</a>
        </h4>
      </div>
      <div id="collapse6" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Dmitry Nikolaev and Sebastian Pado</p>
<p>
The capabilities and limitations of BERT and similar models are still unclear when it comes to learning syntactic abstractions, in particular across languages. In this paper, we use the task of subordinate-clause detection within and across languages to probe these properties. We show that this task is deceptively simple, with easy gains offset by a long tail of harder cases, and that BERT's zero-shot performance is dominated by word-order effects, mirroring the SVO/VSO/SOV typology.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/_eTFgy5QRpg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small" >BiliBili</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP2.pdf" class="button small">Paper PDF</a></p>
       </div>
      </div>
    </div>



   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse7">10:22 &ndash; 10:34 Investigating Information-Theoretic Properties of the Typology of Spatial Demonstratives</a>
        </h4>
      </div>
      <div id="collapse7" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Sihan Chen, Richard Futrell and Kyle Mahowald</p>
<p>
Using data from Nintemann et al. (2020), we explore the variability in complexity and informativity across spatial demonstrative systems using spatial deictic lexicons from 223 languages. We argue from an information-theoretic perspective (Shannon, 1948) that spatial deictic lexicons are efficient in communication, balancing informativity and complexity. Specifically, we find that under an appropriate choice of cost function and need probability over meanings, among all the 21146 theoretically possible spatial deictic lexicons, those adopted by real languages lie near an efficient frontier. Moreover, we find that the conditions that the need probability and the cost function need to satisfy  are consistent with the cognitive science literature regarding the source-goal asymmetry. We also show that the data are better explained by introducing a notion of systematicity, which is not currently accounted for in Information Bottleneck approaches to linguistic efficiency.
</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP4.pdf" class="button small">Paper PDF</a></p>

       </div>
      </div>
    </div>
    
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse8">10:34 &ndash; 10:46 Tweaking UD Annotations to Investigate the Placement of Determiners, Quantifiers
    and Numerals in the Noun Phrase</a>
        </h4>
      </div>
      <div id="collapse8" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Luigi Talamo</p>
<p> We describe a methodology to extract with finer accuracy word order patterns from texts automatically annotated with Universal Dependency (UD) trained parsers. We use the methodology to quantify the word order entropy of determiners, quantifiers and numerals in ten Indo-European languages, using UD-parsed texts from a parallel corpus of prosaic texts. Our results suggest that the combinations of different UD annotation layers, such as UD Relations, Universal Parts of Speech and lemma, and the introduction of language-specific lists of closed-category lemmata has the two-fold effect of improving the quality of analysis and unveiling hidden areas of variability in word order patterns.
</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP7.pdf" class="button small">Paper PDF</a></p>

       </div>
      </div>
    </div>
   
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse9">10:46 &ndash; 10:58 How Universal is Metonymy? Results from a Large-Scale Multilingual Analysis</a>
        </h4>
      </div>
      <div id="collapse9" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Temuulen Khishigsuren, Gábor Bella, Thomas Brochhagen, Daariimaa Marav, Fausto Giunchiglia and Khuyagbaatar Batsuren</p>
<p> Metonymy is regarded by most linguists as a universal cognitive phenomenon, especially since the emergence of the theory of conceptual mappings. However, the field data backing up claims of universality has not been large enough so far to provide conclusive evidence. We introduce a large-scale analysis of metonymy based on a lexical corpus of over 20 thousand metonymy instances from 189 languages and 69 genera. No prior study, to our knowledge, is based on linguistic coverage as broad as ours. Drawing on corpus analysis, evidence of universality is found at three levels: systematic metonymy in general, particular metonymy patterns, and specific metonymy concepts.
</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP9.pdf" class="button small">Paper PDF</a></p>

       </div>
      </div>
    </div>
  
     <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse10">10:58 &ndash; 11:10 Typological Word Order Correlations with Logistic Brownian Motion</a>
        </h4>
      </div>
      <div id="collapse10" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Kai Hartung, Gerhard Jäger, Sören Gröttrup and Munir Georges</p>
<p>In this study we address the question to what extent syntactic word-order traits of different languages have evolved under correlation and whether such dependencies can be found universally across all languages or restricted to specific language families. To do so, we use logistic Brownian Motion under a Bayesian framework to model the trait evolution for 768 languages from 34 language families. We test for trait correlations both in single families and universally over all families. Separate models reveal no universal correlation patterns and Bayes Factor analysis of models over all covered families also strongly indicate lineage specific correlation patters instead of universal dependencies.
</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP5.pdf" class="button small">Paper PDF</a></p>

       </div>
      </div>
    </div>

<br/> 
<h3 style="font-size:21px"><font color="brown">&#10043;</font>&nbsp;Keynote Talk&nbsp;<font color="brown">&#10043;</font></h3><br/>
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse201">11:10 &ndash; 12:00 Graham Neubig: Surprise!</a>
        </h4>
      </div>
      <div id="collapse201" class="panel-collapse collapse">
        <div class="panel-body">
<p>
<img src="workshops/2022/sigtyp/speakers/neubig.jpg" alt="Graham Neubig" style="height:110px;float:left;margin:9px"/>
Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on multilingual natural language processing, natural language interfaces to computers, and machine learning methods for NLP, with the final goal of every person in the world being able to communicate with each-other, and with computers in their own language. He also contributes to making NLP research more accessible through open publishing of research papers, advanced NLP course materials and video lectures, and open-source software, all of which are available on his web site.</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Slides</a>&nbsp;&nbsp;&nbsp;<a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="http://www.phontron.com" class="button small"> Graham's Website</a></p>
	</div>
      </div>
    </div>
  <br/>

   

<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse12">12:00 &ndash; 13:30 Lunch</a>
        </h4>
      </div>
      <div id="collapse12" class="panel-collapse collapse">
        <div class="panel-body">
<p>
Lunch, discussions, etc.
</p>
       </div>
      </div>
    </div>


<br/>
<h3 style="font-size:21px"><font color="orange">&#10043;</font>&nbsp;Shared Task Session&nbsp;<font color="orange">&#10043;</font></h3><br/>

    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse13">13:30 &ndash; 13:50 The SIGTYP 2022 Shared Task on the Prediction of Cognate Reflexes </a>
        </h4>
      </div>
      <div id="collapse13" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Johann-Mattis List, Ekaterina Vylomova, Robert Forkel, Nathan Hill and Ryan Cotterell</p>
<p>This study describes the structure and the results of the SIGTYP 2022 shared task on the prediction of cognate reflexes from multilingual wordlists. We asked participants to submit systems that would predict words in individual languages with the help of cognate words from related languages.  Training and surprise data were based on standardized multilingual wordlists from several language families. Four teams submitted a total of eight systems, including both neural and non-neural systems, as well as systems adjusted to the task and systems using more general settings. While all systems showed a rather promising performance, reflecting the overwhelming regularity of sound change, the best performance throughout was achieved by a system based on convolutional networks originally designed for image restoration.</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP11.pdf" class="button small">Paper PDF</a></p>
       </div>
      </div>
    </div>


    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse14">13:50 &ndash; 14:05 CrossLingference: Bayesian Phylogenetic Cognate Prediction</a>
        </h4>
      </div>
      <div id="collapse14" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Gerhard Jäger</p>
<p>In Jäger (2019) a computational framework was defined to start from parallel word lists of related languages and infer the corresponding vocabulary of the shared proto-language. The SIGTYP 2022 Shared Task is closely related. The main difference is that what is to be reconstructed is not the proto-form but an unknown word from an extant language. The system described here is a re-implementation of the tools used in the mentioned paper, adapted to the current task.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/eQZ9yEDRw3k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">BiliBili</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP12.pdf" class="button small">Paper PDF</a></p>
       </div>
      </div>
    </div>


    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse15">14:05 &ndash; 14:20 Mockingbird: Two Types of Models for the Prediction of Cognate Reflexes </a>
        </h4>
      </div>
      <div id="collapse15" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Christo Kirov, Richard Sproat and Alexander Gutkin</p>
<p>The SIGTYP 2022 shared task concerns the problem of word reﬂex generation in a target language, given cognate words from a subset of related languages. We present two systems to tackle this problem, covering two very different modeling approaches. The ﬁrst model extends transformer-based encoder-decoder sequence-to-sequence modeling, by encoding all available input cognates in parallel, and having the decoder attend to the resulting joint representation during inference. The second approach takes inspiration from the ﬁeld of image restoration, where models are tasked with recovering pixels in an image that have been masked out. For reﬂex generation, the missing reﬂexes are treated as “masked pixels” in an “image” which is a representation of an entire cognate set across a language family. As in the image restoration case, cognate restoration is performed with a convolutional network.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/ZU0SE46VG7Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">BiliBili</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP13.pdf" class="button small">Paper PDF</a></p>
       </div>
      </div>
    </div>


    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse16">14:20 &ndash; 14:35  Leipzig: A Transformer Architecture for the Prediction of Cognate Reflexes</a>
        </h4>
      </div>
      <div id="collapse16" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Giuseppe G. A. Celano</p>
<p>This paper presents the transformer model built to participate in the SIGTYP 2022 Shared Task on the Prediction of Cognate Reflexes. It consists of an encoder-decoder architecture with multi-head attention mechanism. Its output is concatenated with the one hot encoding of the language label of an input character sequence to predict a target character sequence. The results show that the transformer outperforms the baseline rule-based system only partially.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/RG0xVqPmLY0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">BiliBili</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP14.pdf" class="button small">Paper PDF</a></p>
       </div>
      </div>
    </div>

   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse17">14:35 &ndash; 14:50 CEoT: Approaching Reflex Predictions as a Classification Problem Using Extended
Phonological Alignments</a>
        </h4>
      </div>
      <div id="collapse17" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Tiago Tresoldi</p>
<p>This work describes an implementation of the “extended alignment” model for cognate reflex prediction submitted to the “SIGTYP 2022 Shared Task on the Prediction of Cognate Reflexes”. Similarly to List et al. (2022a), the technique involves an automatic extension of sequence alignments with multilayered vectors that encode informational tiers on both site-specific traits, such as sound classes and distinctive features, as well as contextual and suprasegmental ones, conveyed by cross-site referrals and replication. The method allows to generalize the problem of cognate reflex prediction as a classification problem, with models trained using a parallel corpus of cognate sets. A model using random forests is trained and evaluated on the shared task for reflex prediction, and the experimental results are presented and discussed along with some differences to other implementations.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/0IG5N46XhAg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">BiliBili</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP15.pdf" class="button small">Paper PDF</a></p>
       </div>
      </div>
    </div>
<br/> 
<h3 style="font-size:21px"><font color="yellow">&#10043;</font>&nbsp;Linguistic Trivia&nbsp;<font color="yellow">&#10043;</font></h3>
<br/>
   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse11">14:50 &ndash; 15:20 Linguistic Trivia</a>
        </h4>
      </div>
      <div id="collapse11" class="panel-collapse collapse">
        <div class="panel-body">
<p>
Some ice breaking activities :-)
</p>
       </div>
      </div>
    </div>

<div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse18">15:20 &ndash; 15:30 Break</a>
        </h4>
      </div>
      <div id="collapse18" class="panel-collapse collapse">
        <div class="panel-body">
<p>
Coffee break, discussions, etc.
</p>
       </div>
      </div>
    </div>

<br/> 
<h3 style="font-size:21px"><font color="purple">&#10043;</font>&nbsp;Keynote Talk&nbsp;<font color="purple">&#10043;</font></h3><br/>
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse19">15:30 &ndash; 16:20 Isabel Papadimitriou: Learning from our Differences. How Typologically Distinct Modalities of Data
Help Demystify Language Models</a>
        </h4>
      </div>
      <div id="collapse19" class="panel-collapse collapse">
        <div class="panel-body">
<p>
<img src="workshops/2022/sigtyp/speakers/isabel.jpg" alt="Isabel Papadimitriou" style="height:110px;float:left;margin:9px"/>
Isabel is a PhD student at Stanford in the Natural Language Processing group, advised by Dan Jurafsky. Her main research focuses on exploring the linguistic basis of computational language methods. She likes to focus on how language is both a discrete symbolic system and a system of continuous gradations, and exploring the limits of how large neural models can emcompass this combination.
She is very interested in looking at the behavior of large language models in multilingual settings, and analyizing the ways in which languages and dialects co-occur and interfere in single models. <br/>
Looking beyond a single language, or to non-linguistic forms of data, can yield new insights into linguistic representation and use in language models. This talk will explore this theme in two threads: Firstly, what can we learn from passing non-linguistic data through language models? From natural modalities like music to controlled synthetic parentheses languages, we can use datasets with different underlying structures to explore knowledge in language model transfer learning. Knowing the structures in this data lets us understand if and how different features are acquired and generalized in language model training. Secondly, we will look at how typologically-aware analysis can help us understand joint multilingual representation in language models, with experiments that focus on agenthood and case in different languages in multilingual models. The typological diversity of agenthood gives us a handle into understanding how representations can be shared and also separated between languages. Examining language models at the points where diverse data differs – and systematically knowing the ways in which data differs – offers a useful window into how linguistic knowledge is represented in language models.</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Slides</a>&nbsp;&nbsp;&nbsp;<a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="https://nlp.stanford.edu/~isabelvp/" class="button small"> Isabel's Website</a></p>
      </div>
      </div>
    </div>

<br/> 
<h3 style="font-size:21px"><font color="red">&#10043;</font>&nbsp;Databases and Corpora&nbsp;<font color="red">&#10043;</font></h3><br/>



  <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse20">16:20 &ndash; 16:35 A Database for Modal Semantic Typology</a>
        </h4>
      </div>
      <div id="collapse20" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Qingxia Guo, Nathaniel Imel and Shane Steinert-Threlkeld</p>
<p>
 This paper introduces a database for crosslinguistic modal semantics. The purpose of this database is to (1) enable ongoing consolidation of modal semantic typological knowledge into a repository according to uniform data standards and to (2) provide data for investigations in crosslinguistic modal semantic theory and experiments explaining such theories. We describe the kind of semantic variation that the database aims to record, the format of the data, and a current snapshot of the database, emphasizing access and contribution to the database in light of the goals above.  We release the database at https://clmbr.shane.st/modal-typology.
</p>
   <iframe width="560" height="315" src="https://www.youtube.com/embed/BQ_O8TzjSQE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">BiliBili</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP8.pdf" class="button small">Paper PDF</a></p>
       </div>
      </div>
    </div>


  <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse21">16:35 &ndash; 16:47 PaVeDa - Pavia Verbs Database: Challenges and Perspectives</a>
        </h4>
      </div>
      <div id="collapse21" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Chiara Zanchi, Silvia Luraghi and Claudia Roberta Combei</p>
<p>
This paper describes an ongoing endeavor to construct Pavia Verbs Database (PaVeDa), 2013 an open-access typological resource that builds upon previous work on verb argument structure, in particular the Valency Patterns Leipzig (ValPaL) project (Hartmann et al., 2013). The PaVeDa database features four major innovations as compared to the ValPaL database: (i) it includes data from ancient languages enabling diachronic research; (ii) it expands the language sample to language families that are not represented in the ValPaL; (iii) it is linked to external corpora that are used as sources of usage-based examples of stored patterns; (iv) it introduces a new cross-linguistic layer of annotation for valency patterns which allows for contrastive data visualization.</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP10.pdf" class="button small">Paper PDF</a></p>
       </div>
      </div>
    </div>


   <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse22">16:47 &ndash; 17:00 ParaNames: A Massively Multilingual Entity Name Corpus</a>
        </h4>
      </div>
      <div id="collapse22" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By Jonne Sälevä and Constantine Lignos</p>
<p>We present ParaNames, a Wikidata-derived multilingual parallel name resource consisting of names for approximately 14 million entities spanning over 400 languages. ParaNames is useful for multilingual language processing, both in defining tasks for name translation tasks and as supplementary data for other tasks. We demonstrate an application of ParaNames by training a multilingual model for canonical name translation to and from English.</p>
<p  style="font-style:italic;" align="right" color="red"><a href="TBA" class="button small">Recording</a>&nbsp;&nbsp;&nbsp;<a href="https://sigtyp.inf.ethz.ch/channel/general" class="button small">RocketChat</a>&nbsp;&nbsp;&nbsp;<a href="workshops/2022/sigtyp/papers/SIGTYP3.pdf" class="button small">Paper PDF</a></p>
       </div>
      </div>
    </div>
    

<br/>
  <div class="panel-group" id="accordion">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h4 class="panel-title">
          <a data-toggle="collapse" data-parent="#accordion" href="#collapse30" style="font-size:18px">17:00 &ndash; 17:10 Closing Session</a>
        </h4>
      </div>
      <div id="collapse30" class="panel-collapse collapse">
        <div class="panel-body">
<p align="left" style="color:blue"> By SIGTYP2022 Organizing Committee</p>
<p>
Best Paper Award, Closing Remarks, and Future SIGTYP Events Announcement! 
</p>

</div>
      </div>
    </div>

</div>
<br/>
<br/>


<!--p style="font-size:18px">You may also <a href="http://">Read it in PDF</a></p-->

						</section>
					</div>
					
				</div>
			</div>
		</div>
	
	<!-- Copyright -->
		<div id="copyright">
			<div class="container">
				Contact Email: <a href="mailto:sigtyp AT gmail DOT com"> sigtyp AT gmail DOT com </a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  WebMaster: <a href="http://kat.academy">EKATERINA VYLOMOVA</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Design: <a href="http://templated.co">TEMPLATED</a>
			</div>
		</div>


	</body>
</html>
