<!DOCTYPE HTML>
<!--
    Imagination by TEMPLATED
    templated.co @templatedco
    Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>MRL 2023 Shared Task on Multi-lingual Multi-task Information Retrieval</title>
		<link rel="shortcut icon" type="image/x-icon" href="images/favicon.ico" />
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<link href='http://fonts.googleapis.com/css?family=Raleway:400,100,200,300,500,600,700,800,900' rel='stylesheet' type='text/css'>
		<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/skel-panels.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel-noscript.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-desktop.css" />
		</noscript>
	</head>
	<body>

	<div id="header-wrapper">

		<!-- Header -->
			<div id="header">
				<div class="container">
						
					<!-- Logo -->
						<div id="logo">
							<a href="index.html"><img src="images/sigtyp1.jpg"  style="width:70px" alt="SIGTYP"></a>
							<!--h1><a href="#"><font color=red>S</font>IG<font color=red>T</font>YP</a></h1-->
						</div>
					
					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Homepage</a></li>
								<li><a href="constitution.html">Constitution</a></li>
								<li><a href="members.html">Members</a></li>
								<li class="active"><a href="workshop.html">Workshop</a></li>
								<li><a href="lectures.html">Lectures</a></li>
								<li><a href="blog.html">Blog</a></li>
							</ul>
						</nav>
	
				</div>
			</div>
		<!-- Header -->

		<!-- Banner -->
			<div id="banner">
				<div class="container">
	
					<section>
						<!--span class="fa fa-cubes"></span-->
						<header>
							<h2 > </h2>
							<h2 > </h2>
<h2 > </h2>
							<span class="byline"> </span>
						</header>
						<!--a href="#" class="button medium">Fusce ultrices fringilla</a-->
					</section>	
				</div>
			</div>
		<!-- /Banner -->

	</div>

	<!-- Main -->
		<div id="main">
			<div class="container">
				<div class="row">
		
					<div class="9u skel-cell-important">
						<section>
				<header>
				<h4 style="font-size:28px;"> MRL 2023 Shared Task on Multi-lingual Multi-task Information Retrieval</h4> </header>
<br/>
<h3 style="font-size:20px;"> <strong>Description and Objectives </strong></h3>
<br/>

<p  style="font-size:17px">
Large language models continue to demonstrate outstanding performance in many applications that require competence in language understanding and generation. This performance is especially prominent in English, where large amounts of public evaluation benchmarks for various downstream tasks are available. However, the extent to which language models can be reliably deployed in terms of different languages and domains are not still well established. Recent efforts in creating benchmarks, such as the XTREME-UP benchmark, providing extended ranges of languages in large sets of downstream tasks allow a more inclusive setting for studying different characteristics of large language models under different categories and properties of data and domains.

In this new shared task we extend the <a href="https://github.com/google-research/xtreme-up">XTREME-UP</a> benchmark to include various out-of-domain data sets in a selected set of data-scarce and typologically-diverse languages. Our evaluation benchmark consists of the multi-domain public data sets in XTREME-UP, where we provide a multi-task evaluation setting, in particular in the tasks of Named Entity Recognition (NER) and Reading Comprehension (RC), on test sets curated from articles on Wikipedia. The main objective of the shared task is to assess and understand the multilingual characteristics of the inference capability of multilingual language models in understanding and generating language based on logical, factual or causal relationships between knowledge contained over long contexts of text, especially under low-resource settings.
</p>


<h3 style="font-size:20px;"> <strong>Tasks and Evaluation</strong></h3>
<br/>
<p  style="font-size:17px">
With the advancement of language models accessing and processing tons of information in different formats and languages, it has become of great importance to be able to assess the capabilities to access and provide the right information useful to different audiences. In this shared task, we provide a multi-task evaluation format that assesses information retrieval capabilities of language models in terms of two subtasks: named entity recognition and question answering.
</p>
<br/>
<p  style="font-size:17px">
<b>Named Entity Recognition (NER)</b> is a classification task that identifies phrases in a text that refer to entities or predefined categories (such as dates, person, organization and location names) and it is an important capability for information access systems that perform entity look-ups for knowledge verification, spell-checking or localization applications. The XTREME-UP dataset contains processed data from <a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00416/107614">MasakhaNER</a> (Adelani et al., 2021) and <a href="https://arxiv.org/pdf/2210.12391.pdf">MasakhaNER 2.0</a> (Adelani et al., 2022) in the following languages: Amharic, Ghomálá, Bambara, Ewe, Hausa, Igbo, (Lu)Ganda, (Dho)Luo, Mossi (Mooré), Nyanja (Chichewa), Nigerian Pidgin, Kinyarwanda, Shona, Swahili, Tswana (Setswana), Twi, Wolof, Xhosa, Yoruba and Zulu.
The objective of the system is to tag the named entities in a given text as person (PER), organization (ORG), location (LOC), and date (DATE) (Our tag set uses $$ as delimiter).
</p>
<br/>
<p  style="font-size:17px">
<b>Question answering (QA)</b> is an important capability that enables responding to natural language questions with answers found in text. Here we focus on the information-seeking scenario where questions can be asked without knowing the answer—it is the system’s job to locate a suitable answer passage (if any). The information-seeking question-answer pairs tend to exhibit less lexical and morphosyntactic overlap between the question and answer since they are written separately, which is a more suitable setting to evaluate typologically-diverse languages.
Here, the system is given a question, title, and a passage and must provide the answer—if any—or otherwise return that the question has “no answer” in the passage.  The XTREME-UP benchmark currently contains QA data only in Indonesian, Bengali, Swahili and Telugu. The competing systems will therefore be required to infer information from different language annotations.
</p>
<br/>
<p  style="font-size:17px">
<b>Evaluation</b> in the generative task will use character error rate (CER) and character n-gram F-score rather than their word-level counterparts as they enable more fine-grained evaluation and are better suited to morphologically-rich languages. We obtain a final score by averaging the scores of QA and NER, evaluated with F1 accuracy.
</p>

						
<h3 style="font-size:20px;"> <strong>Data and Languages</strong></h3>
<br/>

<p  style="font-size:17px">
The training and validation data sets that can be used for building multi-task information retrieval systems are directly accessible on the XTREME-UP repository. 

The test sets for official evaluation will be released ten days before the submission date, and will be in the following languages: Igbo, Indonesian, Swiss German, Turkish, Uzbek, Yoruba.
We also anticipate that there will be one or two surprise languages in the final test sets.

</p>

<br/>
							
<h3 style="font-size:20px;"> <strong>Participation</strong></h3>
<br/>

<p  style="font-size:17px">
	Interested parties are invited to contact <a href="mailto:mrlw2023@gmail.com">mrlw2023@gmail.com</a> or join the google group <a href="https://groups.google.com/u/1/g/mrl-shared-task-2023">mrl-shared-task-2023@googlegroups.com</a> to be involved in the competition. 

All participating systems will be evaluated together with our baselines against the same held-out test set, to be released shortly before evaluation. Submitted systems can compete in some or all sub-tasks. 
Participating teams will be invited to submit a short paper describing their work to the MRL workshop and to present it in a special session in the workshop. Paper submissions must follow the EMNLP paper format and sent to <strong><a href="https://softconf.com/emnlp2023/mrl2023">Softconf Conference Link of MRL 2023</a></strong> before the paper submission deadline.
<br/>
</p>

<h3 style="font-size:20px;"> <strong>Important dates</strong></h3>
<br/>


<p  style="font-size:17px">
	September 1, 2023: Release of testing data 
	<br/>
	August 20, 2023: Deadline to release external data and resources used in systems 
	<br/>
	September 10, 2023: Deadline for submission of systems
	<br/>
	September 20, 2023: Release of rankings and results
	<br/>
	September 30, 2023: Deadline for submitting system description papers
	<br/>
	October 7, 2023: Paper notifications 
	<br/>
	October 21, 2023: Camera-ready papers and posters due 
	<br/>
	December 7, 2023: Workshop 
	<br/>
</p>

<h3 style="font-size:20px;"> <strong>Ranking</strong></h3>
<br/>

<p  style="font-size:17px">
	The systems will be evaluated based on the global ranking on all benchmark languages. Participants can submit systems that are language-specific (monolingual) and their systems will be evaluated as a partial submission to the specific language their system is trained on. 

</p>

<h3 style="font-size:20px;"> <strong>Additional resources</strong></h3>
<br/>
<p  style="font-size:17px">
		The shared task allows participants to use external resources or tools as long as they are openly available and can be, in theory, used by other participants for research purposes. In case participants decide to use external resources and data in their system they should contact the organizers in case the specific resources would be permitted, in such cases specific information on the used resources and how they can be obtained should be shared via email by August 20th, 2023.
	
</p>


<h3 style="font-size:20px;"> <strong>Organizers</strong></h3>
<br/>

<p  style="font-size:17px">
	
	David Adelani, UCL and Google Deepmind
	<br/>
	Duygu Ataman, New York University
	<br/>	
	Chris Emezue, TU Munich and MILA
	<br/>
	Omer Goldman, Bar Ilan University
	<br/>
	Mammad Hajili, Microsoft
	<br/>
	Sebastian Ruder, Google Deepmind
	<br/>
	Francesco Tinner, University of Amsterdam
	<br/>
	Genta Indra Winata, Bloomberg
	<br/>
	
</p> 
						

<h3 style="font-size:20px;"> <strong>Shared Task Prize</strong></h3>
<br/>
<p  style="font-size:17px">
The winning team will receive an award of 500 USD and will be given a presentation during the workshop.
	<br/>

</p> 

<h2  style="font-size:27px">Sponsors</h2> </header>
<br/>


<a href="http://google.com"><img src="images/Google_Logo.png" style="width:200px" alt="Google"></a>
<p  style="font-size:17px"> Interested in being a Sponsor?  <a href="mailto:mrlw2023@gmail.com">Contact us!</a> </p>

</section>
</div>
					
					<div class="3u">
						<section class="sidebar">
							<header>
								<h2>Workshops</h2>
							</header>
							<ul class="default">
								<li><a href="ws2023-mrl.html">&raquo; MRL 2023</a></li>
								<li><a href="ws2023-sigtyp.html">&raquo; SIGTYP 2023</a></li>
								<li><a href="ws2022-sigtyp.html">&raquo; SIGTYP 2022</a></li>
								<li><a href="ws2022-mrl.html">&raquo; MRL 2022</a></li>
								<li><a href="ws2021.html">&raquo; SIGTYP 2021</a></li>
								<li><a href="ws2020.html">&raquo; SIGTYP 2020</a></li>
								<li><a href="ws2019.html">&raquo; TyP-NLP 2019</a></li>
							</ul>
							<br/><br/>
							<header>
								<h2>Shared Tasks</h2>
							</header>
							<ul class="default">
								<li><a href="st2023.html">&raquo; 2023: Cognate and Derivative Detection for Low-Resourced Languages</a></li>
								<li><a href="st2022.html">&raquo;2022: Prediction of Cognate Reflexes</a></li>
								<li><a href="st2022-mrl.html">&raquo;  <font color="red">2022 (MRL): Multilingual Clause-level Morphology</font></a></li>
								<li><a href="st2021.html">&raquo; 2021: Robust Language ID from Speech</a></li>
								<li><a href="st2020.html">&raquo; 2020: Prediction of Typological Features</a></li>
							</ul>
						</section>
						
					</div>
				
				</div>
			</div>
		</div>
	<!-- Main -->

	
	<!-- Copyright -->
		<div id="copyright">
			<div class="container">
				Contact Email: <a href="mailto:mattis_list@eva.mpg.de">Mattis List</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  WebMaster: <a href="http://kat.academy">EKATERINA VYLOMOVA</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Design: <a href="http://templated.co">TEMPLATED</a>
			</div>
		</div>


	</body>
</html>
